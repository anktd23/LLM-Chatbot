A stochastic block model for community detection in attributed networks Xiao Wang a, Fang Dai a, *, Wenyan Guo a, Junfeng Wang a a School of Science, Xiâ€™an University of Technology, Xiâ€™an, China E-mail addresses: daifang@xaut.edu.cn (Dai Fang) 2210920031@stu.xaut.edu.cn (Xiao Wang) Abstractâ€”Community detection is an important content in complex network analysis. The existing community detection methods in attributed networks mostly focus on only using network structure, while the methods of integrating node attributes is mainly for the traditional community structures, and cannot detect multipartite structures and mixture structures in network. In addition, the model-based community detection methods currently proposed for attributed networks do not fully consider unique topology information of nodes, such as betweenness centrality and clustering coefficient. Therefore, a stochastic block model that integrates betweenness centrality and clustering coefficient of nodes for community detection in attributed networks, named BCSBM, is proposed in this paper. Different from other generative models for attributed networks, the generation process of links and attributes of nodes in BCSBM model follows the Poisson distribution, and the probability between community is considered based on the stochastic block model. Moreover, the betweenness centrality and clustering coefficient of nodes are introduced into the process of links and attributes of nodes generation. Finally, the expectation maximization algorithm is employed to estimate the parameters of the BCSBM model, and the node-community memberships in network is obtained through the hard division process, so the community detection is completed. By experimenting on six real-work networks containing different network structures, and comparing with the community detection results of five algorithms, the experimental results show that the BCSBM model not only inherits the advantages of the stochastic block model and can detect various network structures, but also has good data fitting ability due to introducing the betweenness centrality and clustering coefficient of nodes. Overall, the performance of this model is superior to other five compared algorithms. Keyworks stochastic block model; attributed network; community detection; betweenness centrality; clustering coefficient1. Introduction An attributed network refers to a network in which the nodes or edges contain attribute information. [1].Unlike non-attributed networks that only consider the links between nodes, attributed network can model the characteristics or attributes of nodes in complex systems and provide much richer and heterogeneous information [2]. For example, in social networks, attributes can provide information about individuals' age, gender, interests, occupation, and location. In academic citation networks, attributes contain important information such as titles, authors, abstract, keywords, etc. Therefore, the studying of attributed networks is very significant to the theoretical research and application of complex systems in the real world. Recently, the community detection in attributed networks has attracted widespread attention from researchers. Zhou et al. [4] proposed the SA-Cluster algorithm, which uses a unified distance measure to combine topology structures and attributes to construct a weighted network, and employed a clustering algorithm based on K- Medoids [5] to mine the community structure in the weighted network. This algorithms is similarity-based for community detection in attributed networks, the relevant algorithms are SAGL [6], PWMN [7], ANCA [8] and SAS-LP [9]. In addition, Wang et al. [10] proposed the SCI algorithm, which uses a two-factor non-matrix factorization method to extract the node memberships matrix from the attribute matrix and adjacency matrix to achieve community detection. The algorithm is based on non-negative matrix factorization for community detection in attributed networks, the related algorithms are PICS [11], SCD [12], MDNMF [13] and TENE [14]. These above algorithms are widely applied to detect communities with assortative structures shown as Fig. 1(a), i.e., tight intra-community node links and relatively sparse inter-community node links [15]. However, in the real world, there are not only assortative structures but also disassortative structures [16], such as multipartite structures shown as Fig. 1(b) (node links within communities are sparse, and node links between communities are reversely densely), and mixture structures such as Fig. 1(c) (It contains both community structure and multipartite structures). Currently, the main approach that can deal with both assortative networks and disassortative networks is stochastic block model (SBM) [18]. The SBM is a common model for characterizing networks with complex structural patterns, such as community, multipartite and mixture structures. Chai et al.[19] inherited the advantages of general stochastic block model (GSB) [20] and popularity and productivity link model (PPL) [21], introduced the popularity and productivity of nodes to simulate the scale-free properties of real networks and proposed PPSB_DC model. A two-stage projection algorithm is used to estimate model parameters for PPSB_DC, but a recent study found [22]: this two-stage algorithm does not guarantee convergence. Chen et al. [23] proposed BNPA model based on Newman's mixture models (NMM) [24] and Bayesian nonparametric theory. This model not only makes full use of the links between nodes and attributes of nodes to divide communities by sharing hidden variables, but also employs Bayesian nonparametric theory to determine the number of communities automatically, whichFig.1 Examples of assortative and disassortative networks [17] (a) assortative network with community structures; (b) disassortative network with multipartite structures; (c) disassortative network with mixture structures solves the problem of other methods that need to define the number of communities in advance, but it may be inaccurate to infer the number of communities, which will affect the accuracy of community detection. He et al. [25] proposed NEMBP model, which combines degree-corrected stochastic block model (DSBM) [26] and multinomial distributions to model the generation process of links and attributes to better fit the real network. The model parameters are inferred by using the nested Expectation-Maximum (EM) algorithm [27] and belief propagation (BP) [28]. Compared to the EM algorithm alone, the solution complexity of the NEMBP model is higher. Chen et al. [29] proposed subspace stochastic block model (SSB), which not only incorporates the attributes of nodes into the GSB model in the form of probabilities, but also constructs a hidden network by integrating the topology information and attribute information in the process of generating links between nodes. In this hidden network, it is possible to generate links between all nodes, avoiding the consideration of unobserved edges, thus avoiding the negative sampling strategy. Chang et al. [22] proposed PSB_PG model, which constructs a generative model based on the potential relationship between links and attributes of nodes. However, since real networks have scale-free property, the degree of nodes follows power-law distribution, Zheng et al. [30] introduced the degree of nodes on the basis of PSB_PG and proposed the degree-corrected stochastic block model for attributed networks (DPSB_PG). However, these two models do not fully consider the unique topological information of nodes, such as betweenness centrality and clustering coefficient, etc. According to the assumption of consistency between node attributes and topology structure, it can be seen that topological information of nodes often has a great correlation with the topology structures and can affect the links between nodes. Based on the DPSB_PG, an attributed network stochastic block model BCSBM that integrates betweenness centrality and clustering coefficient of nodes is presented in this paper, which comprehensively considers the importance of nodes and the property of node neighborhood structure. The betweenness centrality characterizes the importance of nodes by the number of shortest paths passing through a node and also describes the influence of nodes on the flow of information on the network. The clustering coefficient describes the likelihood that neighboring nodes of individuals inthe network are also neighbors of each other and is used to measure the extent of node clustering. In the BCSBM, the generation of network structures and node attributes follow the Poisson distribution and are independent of each other. It is worth noting that the BCSBM model in this paper is an extension of the DPSB_PG model, and its main difference is that the two observation variables of betweenness centrality and clustering coefficient of nodes are introduced, and the performance of the model is analyzed during the experiments. The paper is organized as follows. In Section 2, we introduce the BCSBM model. In Section 3, the parameters estimation of the BCSBM model by the EM algorithm is described. The process of community detection based on the BCSBM model is presented in Section 4. In Section 5, we give the analysis of the community detection results. Finally, we conclude our work and discuss future in Section 6. 2. BCSBM Model Let ğ·ï¿½ï¿½ï¿½(ğ‘‰, ğ·ï¿½ï¿½ï¿½, ğ‘‰ï¿½ï¿½ï¿½) denotes an undirected and unweighted attributed network, where ğ‘‰ = {1, 2, â‹¯ , ğ‘–ï¿½ï¿½ï¿½} denotes the set of ğ‘–ï¿½ï¿½ï¿½ nodes in the network and ğ·ï¿½ï¿½ï¿½ = {ğ‘ï¿½ï¿½ï¿½1, ğ‘ï¿½ï¿½ï¿½2, â‹¯ , ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½} denotes the set of ğ‘–ï¿½ï¿½ï¿½ edges in the network. If the attribute of each node is denoted by a ğ¾ dimension vector, the attribute matrix of all nodes can be expressed as ğ‘‰ï¿½ï¿½ï¿½ = (ğ‘¥ğ‘–ğ‘–ï¿½ï¿½ï¿½)ğ‘–ï¿½ï¿½ï¿½Ã—ğ¾, where ğ‘¥ğ‘–ğ‘–ï¿½ï¿½ï¿½ = 1 denotes node ğ‘– has ğ‘–ï¿½ï¿½ï¿½ th attribute, otherwise ğ‘¥ğ‘–ğ‘–ï¿½ï¿½ï¿½ = 0 . Typically, the adjacency matrix of an undirected unweighted network is denoted by ğ´ = (ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½)ğ‘–ï¿½ï¿½ï¿½Ã—ğ‘–ï¿½ï¿½ï¿½ , where ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ = 1 denotes node ğ‘– links to node ğ‘–ï¿½ï¿½ï¿½ , otherwise ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ = 0. Suppose a network ğ·ï¿½ï¿½ï¿½ has ğ‘ï¿½ï¿½ï¿½ different communities ğ‘‰1, ğ‘‰2, â‹¯ , ğ‘‰ğ‘Ÿ and ğ‘‰ = â‹ƒ ğ‘‰ğ‘Ÿ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ=1 . 2.1 A generative model for integrating node topology information In a standard stochastic block model [18], the stochastic block probability matrix Î˜ = (ğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½)ğ‘ï¿½ï¿½ï¿½Ã—ğ‘ï¿½ï¿½ï¿½ controls the probability of generating links in network, where ğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ is the connecting probability of two nodes ğ‘– âˆˆ ğ‘‰ğ‘Ÿ and ğ‘–ï¿½ï¿½ï¿½ âˆˆ ğ‘‰ğ‘Ÿï¿½ï¿½ï¿½ and is only related to the communities to which ğ‘– and ğ‘–ï¿½ï¿½ï¿½ belong. In the PSB_PG model [22], Chang et al. relaxed this restriction by introducing a node-community memberships matrix ğ· = (ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ)ğ‘–ï¿½ï¿½ï¿½Ã—ğ‘ï¿½ï¿½ï¿½, where ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ is the probability that a node ğ‘– belongs to the ğ‘ï¿½ï¿½ï¿½th community ğ‘‰ğ‘Ÿ. In the DPSB_PG model [30], Zheng et al. introduced the degree of nodes into the PSB_PG model to influence the generation of network links. In the BCSBM model of this paper, the generation of links in network is strengthened by introducing betweenness centrality and clustering coefficient of nodes to affect the distribution of community. A link between pair of nodes in network is not only related to the node-community memberships matrix ğ·, the inter-community probability matrix Î˜ and the degree of nodes Î“ = (ğ‘–ï¿½ï¿½ï¿½ğ‘–)ğ‘–ï¿½ï¿½ï¿½Ã—1 , but also affected by the betweenness centrality of nodes Î’ = (ğ‘ï¿½ï¿½ï¿½ğ‘–)ğ‘–ï¿½ï¿½ï¿½Ã—1 and clustering coefficient of nodes Îœ = (ğ‘ï¿½ï¿½ï¿½ğ‘–)ğ‘–ï¿½ï¿½ï¿½Ã—1 . So, we introduce betweenness centrality and clustering coefficient of nodes to control the network generation process, the real network can be better fitted. Assuming that the generation of links between pairs of nodes (ğ‘¥, ğ‘¥ï¿½ï¿½ï¿½) is independent and follows the Poisson distribution, the expected number of links that nodes ğ‘– and node ğ‘–ï¿½ï¿½ï¿½ lies incommunities ğ‘‰ğ‘Ÿ and ğ‘‰ğ‘Ÿï¿½ï¿½ï¿½ is ğ‘–ï¿½ï¿½ï¿½Ì‚ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ = ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ğ›¾ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½ where ğ›¾ï¿½ï¿½ï¿½ğ‘– = ğ‘–ï¿½ï¿½ï¿½ğ‘– + ğ‘ï¿½ï¿½ï¿½ğ‘– + ğ‘ï¿½ï¿½ï¿½ğ‘– , ğ‘ï¿½ï¿½ï¿½ğ‘– = 2ğ‘–ï¿½ï¿½ï¿½ğ‘– ğ‘–ï¿½ï¿½ï¿½ğ‘–(ğ‘–ï¿½ï¿½ï¿½ğ‘–âˆ’1) is the clustering coefficient of node ğ‘– [31] , ğ‘ï¿½ï¿½ï¿½ğ‘– = âˆ‘ ğ‘–ï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½ ğ‘– ğ‘Ÿï¿½ï¿½ï¿½,ğ‘Ÿï¿½ï¿½ï¿½â‰ ğ‘– ğ‘”ğ‘Ÿï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½ is the betweenness centrality of node ğ‘– [32], ğ‘–ï¿½ï¿½ï¿½ğ‘– is the degree of node ğ‘–, ğ‘–ï¿½ï¿½ï¿½ğ‘– is the total real links number of node ğ‘–â€™s neighbors, ğ‘”ğ‘Ÿï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½ is the number of shortest paths between nodes ğ‘ï¿½ï¿½ï¿½ and ğ‘ï¿½ï¿½ï¿½, ğ‘–ï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½ ğ‘– is the number of those shortest paths that include node ğ‘–. Considering all communities, the expected total number of links between nodes ğ‘– and ğ‘–ï¿½ï¿½ï¿½ is ğ‘–ï¿½ï¿½ï¿½Ì‚ğ‘–ğ‘–ï¿½ï¿½ï¿½ = âˆ‘ ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ğ›¾ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ,ğ‘Ÿï¿½ï¿½ï¿½=1 where Î˜ is symmetrical, âˆ‘ ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ ğ‘–ï¿½ï¿½ï¿½ ğ‘–=1 =1 and âˆ‘ ğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ,ğ‘Ÿï¿½ï¿½ï¿½=1 = 1 satisfy the normalization constraints. Suppose the generation of links is independent and the number of links follows the Poisson distribution with mean value ğ‘–ï¿½ï¿½ï¿½Ì‚ğ‘–ğ‘–ï¿½ï¿½ï¿½, given the parameters ğ·, Î˜ and observed variables ğ‘…ï¿½ï¿½ï¿½, the probability of generating a network is ğ‘ƒ(ğ´|ğ·, Î˜, ğ‘…ï¿½ï¿½ï¿½) = âˆ (âˆ‘ ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ğ›¾ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ,ğ‘Ÿï¿½ï¿½ï¿½=1 ) ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½! exp (âˆ’ âˆ‘ ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ğ›¾ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ,ğ‘Ÿï¿½ï¿½ï¿½=1 ) ğ‘–ï¿½ï¿½ï¿½ ğ‘–,ğ‘–ï¿½ï¿½ï¿½=1,ğ‘–<ğ‘–ï¿½ï¿½ï¿½ Ã— âˆ (1 2 ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœƒğ‘Ÿğ‘Ÿğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ)ğ‘ğ‘–ğ‘–/2 (ğ‘ğ‘–ğ‘–/2)! ğ‘–ï¿½ï¿½ï¿½ ğ‘–=1 exp (âˆ’ 1 2 âˆ‘ ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœƒğ‘Ÿğ‘Ÿğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ=1 ) (1) where ğ‘…ï¿½ï¿½ï¿½ = â‹ƒ {ğ‘–ï¿½ï¿½ï¿½ğ‘–, ğ‘ï¿½ï¿½ï¿½ğ‘–, ğ‘ï¿½ï¿½ï¿½ğ‘–} ğ‘–ï¿½ï¿½ï¿½ ğ‘–=1 is the set of degree ğ‘–ï¿½ï¿½ï¿½ğ‘– , clustering coefficient ğ‘ï¿½ï¿½ï¿½ğ‘– and betweenness centrality ğ‘ï¿½ï¿½ï¿½ğ‘– of the nodes. 2.2 A generative model for integrating node attribute information Generally, the attributes corresponding to each node in attributed networks are high-dimensional, and whether the nodes in the community have common attributes is sparse. If the attributes of nodes in a community are highly correlated, they will also be consistent or complementary to the network topology structures, promoting the formation of community. Therefore, the generation of node attributes follows the Poisson distribution according to Poissonâ€™ theorem [39]. Let ğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½ denote the probability that a community ğ‘‰ğ‘Ÿ has the ğ‘–ï¿½ï¿½ï¿½ th attribute, and Î¦ = (ğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½)ğ‘ï¿½ï¿½ï¿½Ã—ğ¾ denote community-related attributes matrix. Similarly, nodes ğ‘– in the community ğ‘‰ğ‘Ÿ possessing ğ‘–ï¿½ï¿½ï¿½ th attribute related to degree ğ‘–ï¿½ï¿½ï¿½ğ‘– , betweenness centrality ğ‘ï¿½ï¿½ï¿½ğ‘– , clustering coefficient ğ‘ï¿½ï¿½ï¿½ğ‘– , node-community memberships ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ and community-related attributes ğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½. And for this reason, the propensity of node ğ‘– in the community ğ‘‰ğ‘Ÿ possessing the ğ‘–ï¿½ï¿½ï¿½th attribute is ğ‘‰ï¿½ï¿½ï¿½Ì‚ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ = ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½Summing over all communities ğ‘‰ğ‘Ÿ, the mean propensity of node ğ‘– possessing the ğ‘–ï¿½ï¿½ï¿½th attribute is ğ‘‰ï¿½ï¿½ï¿½Ì‚ğ‘–ğ‘–ï¿½ï¿½ï¿½ = âˆ‘ ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ=1 where âˆ‘ ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ ğ‘–ï¿½ï¿½ï¿½ ğ‘–=1 = 1 and âˆ‘ ğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½ = 1 ğ¾ ğ‘–ï¿½ï¿½ï¿½=1 satisfy the normalization constraints. According to the Poisson distribution process, given the parameter matrix ğ·, Î¦ and the observed variables ğ‘…ï¿½ï¿½ï¿½ = â‹ƒ {ğ‘–ï¿½ï¿½ï¿½ğ‘–, ğ‘ï¿½ï¿½ï¿½ğ‘–, ğ‘ï¿½ï¿½ï¿½ğ‘–} ğ‘–ï¿½ï¿½ï¿½ ğ‘–=1 , the probability ğ‘ƒ(ğ‘‰ï¿½ï¿½ï¿½|ğ·, Î˜, ğ‘…ï¿½ï¿½ï¿½) of generating node attributes in network is ğ‘ƒ(ğ‘‰ï¿½ï¿½ï¿½|ğ·, Î˜, ğ‘…ï¿½ï¿½ï¿½) = âˆ âˆ (âˆ‘ ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ=1 )ğ‘¥ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘¥ğ‘–ğ‘–ï¿½ï¿½ï¿½! exp (âˆ’ âˆ‘ ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ=1 ) ğ¾ ğ‘–ï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–=1 (2) 2.3 Integrating node topology and attribute information Assuming that the generative process of the adjacency matrix ğ´ and attribute matrix ğ‘‰ï¿½ï¿½ï¿½ in network are independent of each other, the joint probability is ğ‘ƒ(ğ´, ğ‘‰ï¿½ï¿½ï¿½|ğ·, Î˜, Î¦, ğ‘…ï¿½ï¿½ï¿½) = ğ‘ƒ(ğ´|ğ·, Î˜, ğ‘…ï¿½ï¿½ï¿½) Ã— ğ‘ƒ(ğ‘‰ï¿½ï¿½ï¿½|ğ·, Î¦, ğ‘…ï¿½ï¿½ï¿½) = âˆ (âˆ‘ ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ğ›¾ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ,ğ‘Ÿï¿½ï¿½ï¿½=1 ) ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½! exp ğ‘–ï¿½ï¿½ï¿½ ğ‘–,ğ‘–ï¿½ï¿½ï¿½=1,ğ‘–<ğ‘–ï¿½ï¿½ï¿½ (âˆ’ âˆ‘ ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ğ›¾ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ,ğ‘Ÿï¿½ï¿½ï¿½=1 ) Ã— âˆ (1 2 âˆ‘ ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœƒğ‘Ÿğ‘Ÿğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ=1 ) ğ‘ğ‘–ğ‘– 2 (ğ‘ğ‘–ğ‘– 2 ) ! exp (âˆ’ 1 2 âˆ‘ ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœƒğ‘Ÿğ‘Ÿğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ=1 ) ğ‘–ï¿½ï¿½ï¿½ ğ‘–=1 Ã— âˆ âˆ (âˆ‘ ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ=1 )ğ‘¥ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘¥ğ‘–ğ‘–ï¿½ï¿½ï¿½! exp (âˆ’ âˆ‘ ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½) ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ=1 ) ğ¾ ğ‘–ï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–=1 (3) The generative process of integrating topology information and attribute information of nodes in network can be summarized as follows. 1) Extracting nodes ğ‘– and ğ‘–ï¿½ï¿½ï¿½ from the communities ğ‘‰ğ‘Ÿ and ğ‘‰ğ‘Ÿï¿½ï¿½ï¿½ with probability ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ and ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½, respectively. 2) Forming a link between node ğ‘– and node ğ‘–ï¿½ï¿½ï¿½ with probability ğ‘–ï¿½ï¿½ï¿½ğ‘–ğ‘–ï¿½ï¿½ï¿½ , where ğ‘–ï¿½ï¿½ï¿½ğ‘–ğ‘–ï¿½ï¿½ï¿½~ğ‘ƒğ‘–ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½(ğ‘–ï¿½ï¿½ï¿½Ì‚ğ‘–ğ‘–ï¿½ï¿½ï¿½). 3) Selecting an attribute ğ‘–ï¿½ï¿½ï¿½ in the community ğ‘‰ğ‘Ÿ with probability ğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½. 4) Selecting an attribute ğ‘–ï¿½ï¿½ï¿½ for the node ğ‘– with probability ğ‘‰ï¿½ï¿½ï¿½ğ‘–ğ‘–ï¿½ï¿½ï¿½ , where ğ‘‰ï¿½ï¿½ï¿½ğ‘–ğ‘–ï¿½ï¿½ï¿½~ğ‘ƒğ‘–ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½(ğ‘‰ï¿½ï¿½ï¿½Ì‚ğ‘–ğ‘–ï¿½ï¿½ï¿½). The corresponding probabilistic graph model is shown in Fig 2.Fig.2 The probabilistic graph model for BCSBM Fig.2 The probabilistic graph model for BCSBM 3. Estimating parameters of BCSBM model using the EM algorithm The model BCSBM contains observed variables ğ´, ğ‘‰ï¿½ï¿½ï¿½, ğ‘…ï¿½ï¿½ï¿½, hidden variables Q = (ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½)ğ‘–ï¿½ï¿½ï¿½Ã—ğ‘–ï¿½ï¿½ï¿½ ,Î¥ = ( ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ )ğ‘–ï¿½ï¿½ï¿½Ã—ğ‘ï¿½ï¿½ï¿½ , and model parameters ğ· = (ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ)ğ‘–ï¿½ï¿½ï¿½Ã—ğ‘ï¿½ï¿½ï¿½ , Î˜ = (ğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½)ğ‘ï¿½ï¿½ï¿½Ã—ğ‘ï¿½ï¿½ï¿½ , Î¦ = (ğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½)ğ‘ï¿½ï¿½ï¿½Ã—K. Due to the existence of hidden variables in the model, the likelihood function cannot be solved directly, and the EM algorithm [27] is the most common hidden variable estimation method, which can handle such problems well. Therefore, in this paper, the EM algorithm is employed to estimate the parameters of the BCSBM model. The inference process is as follows. Considering the logarithm of the Eq. (3), neglecting the constants and terms independent of model parameters, we have ğ¾ï¿½ï¿½ï¿½(ğ·, Î˜, Î¦) = âˆ‘ [1 2 ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ln ( âˆ‘ ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ğ›¾ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ,ğ‘Ÿï¿½ï¿½ï¿½=1 ) âˆ’ 1 2 âˆ‘ ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ğ›¾ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ,ğ‘Ÿï¿½ï¿½ï¿½=1 ] ğ‘–ï¿½ï¿½ï¿½ ğ‘–,ğ‘–ï¿½ï¿½ï¿½=1 + âˆ‘ âˆ‘ âˆ‘ [ğ‘¥ğ‘–ğ‘–ï¿½ï¿½ï¿½ ln (âˆ‘ ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ=1 ) âˆ’ âˆ‘ ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ=1 ] ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ=1 ğ¾ ğ‘–ï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–=1 (4) In E-step, given the parameters ğ·, Î˜ and Î¦ , and the lower bound of the log- likelihood obtained by Jensen's inequality is ğ¾ï¿½ï¿½ï¿½Ì…(ğ·, Î˜, Î¦) = 1 2 âˆ‘ âˆ‘ [ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ ln (ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ğ›¾ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½ ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ ) âˆ’ ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ğ›¾ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½] ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ,ğ‘Ÿï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–,ğ‘–ï¿½ï¿½ï¿½=1 + âˆ‘ âˆ‘ âˆ‘ [ğ‘¥ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ ln (ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½ ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ ) âˆ’ ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½] ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ=1 ğ¾ ğ‘–ï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–=1 (5) whereğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ = (ğ‘–ï¿½ï¿½ï¿½ğ‘– + ğ‘ï¿½ï¿½ï¿½ğ‘– + ğ‘ï¿½ï¿½ï¿½ğ‘–)ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½(ğ‘–ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ + ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ + ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½)ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½ âˆ‘ (ğ‘–ï¿½ï¿½ï¿½ğ‘– + ğ‘ï¿½ï¿½ï¿½ğ‘– + ğ‘ï¿½ï¿½ï¿½ğ‘–)ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½(ğ‘–ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ + ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ + ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½)ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ,ğ‘Ÿï¿½ï¿½ï¿½=1 (6) ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ = (ğ‘–ï¿½ï¿½ï¿½ğ‘– + ğ‘ï¿½ï¿½ï¿½ğ‘– + ğ‘ï¿½ï¿½ï¿½ğ‘–)ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½ âˆ‘ (ğ‘–ï¿½ï¿½ï¿½ğ‘– + ğ‘ï¿½ï¿½ï¿½ğ‘– + ğ‘ï¿½ï¿½ï¿½ğ‘–)ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ=1 (7) ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ denotes the probability that nodes ğ‘– and ğ‘–ï¿½ï¿½ï¿½ lie in communities ğ‘‰ğ‘Ÿ and ğ‘‰ğ‘Ÿï¿½ï¿½ï¿½ , respectively, and there is a link between nodes ğ‘– and ğ‘–ï¿½ï¿½ï¿½; ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ denotes the probability that node ğ‘– in the community ğ‘‰ğ‘Ÿ and has the ğ‘–ï¿½ï¿½ï¿½th attribute. In M-step, given the hidden variables ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ and ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ , and we can obtain the three parameter estimates ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ, ğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½, ğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½ according to the Lagrange multiplier method as follows ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ = âˆ‘ âˆ‘ ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ + 2 Ã— âˆ‘ ğ‘¥ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ ğ¾ ğ‘–ï¿½ï¿½ï¿½=1 ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–ï¿½ï¿½ï¿½=1 (ğ‘–ï¿½ï¿½ï¿½ğ‘– + ğ‘ï¿½ï¿½ï¿½ğ‘– + ğ‘ï¿½ï¿½ï¿½ğ‘–) Ã— [âˆ‘ âˆ‘ ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ + 2 Ã— âˆ‘ âˆ‘ ğ‘¥ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ ğ¾ ğ‘–ï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–=1 ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–,ğ‘–ï¿½ï¿½ï¿½=1 ] (8) ğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ = âˆ‘ ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ ğ‘–ï¿½ï¿½ï¿½ ğ‘–,ğ‘–ï¿½ï¿½ï¿½=1 âˆ‘ âˆ‘ ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ,ğ‘Ÿï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–,ğ‘–ï¿½ï¿½ï¿½=1 ğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½ = âˆ‘ ğ‘¥ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ ğ‘–ï¿½ï¿½ï¿½ ğ‘–=1 âˆ‘ âˆ‘ ğ‘¥ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ ğ¾ ğ‘–ï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–=1 (9) The derivation of the parameters ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ, ğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½, ğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½ can be found in Appendix A. The specific steps of the parameter estimation are shown in Algorithm 1. Algorithm 1 Parameter Inference Algorithm for BCSBM Input: the adjacency matrix ğ´, the attribute matrix ğ‘‰ï¿½ï¿½ï¿½, the number of communities ğ‘ï¿½ï¿½ï¿½, the maximum iteration ğ¼ğ‘‡ and the threshold ğœ•ï¿½ï¿½ï¿½. Output: the model parameters ğ·, Î˜, Î¦ 1: According to the adjacency matrix ğ´, calculate the degree of node ğ‘–ï¿½ï¿½ï¿½ğ‘–, betweenness centrality of node ğ‘ï¿½ï¿½ï¿½ğ‘– , and clustering coefficient of node ğ‘ï¿½ï¿½ï¿½ğ‘–, ğ‘– = 1,2, â‹¯ , ğ‘–ï¿½ï¿½ï¿½. 2: Initialize ğ·(0), Î˜(0), Î¦(0). 3: Compute the objective function ğ¾ï¿½ï¿½ï¿½(0) = (ğ·(0), Î˜(0), Î¦(0)) by Eq. (4). 4: for ğ‘ï¿½ï¿½ï¿½ = 1:ğ¼ğ‘‡ do 5: E-step: Compute ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½, ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ by Eq. (6) ~ (7). ğ‘–, ğ‘–ï¿½ï¿½ï¿½ = 1,2, â‹¯ , ğ‘–ï¿½ï¿½ï¿½; ğ‘ï¿½ï¿½ï¿½, ğ‘ï¿½ï¿½ï¿½ = 1,2, â‹¯ , ğ‘ï¿½ï¿½ï¿½. 6: M-step: Compute ğ·(ğ‘Ÿï¿½ï¿½ï¿½), Î˜(ğ‘Ÿï¿½ï¿½ï¿½), Î¦(ğ‘Ÿï¿½ï¿½ï¿½) by Eq. (8) ~ (9). 7: Compute the objective function ğ¾ï¿½ï¿½ï¿½(ğ‘Ÿï¿½ï¿½ï¿½) = (ğ·(ğ‘Ÿï¿½ï¿½ï¿½), Î˜(ğ‘Ÿï¿½ï¿½ï¿½), Î¦(ğ‘Ÿï¿½ï¿½ï¿½)) by Eq. (4). 8: if |ğ¾ï¿½ï¿½ï¿½(ğ‘Ÿï¿½ï¿½ï¿½)(ğ·(ğ‘Ÿï¿½ï¿½ï¿½), Î˜(ğ‘Ÿï¿½ï¿½ï¿½), Î¦(ğ‘Ÿï¿½ï¿½ï¿½)) âˆ’ ğ¾ï¿½ï¿½ï¿½(ğ‘Ÿï¿½ï¿½ï¿½âˆ’1)(ğ·(ğ‘Ÿï¿½ï¿½ï¿½âˆ’1), Î˜(ğ‘Ÿï¿½ï¿½ï¿½âˆ’1), Î¦(ğ‘Ÿï¿½ï¿½ï¿½âˆ’1))| < ğœ•ï¿½ï¿½ï¿½ or ğ‘ï¿½ï¿½ï¿½ = ğ¼ğ‘‡ then 9: ğ· = ğ·(ğ‘Ÿï¿½ï¿½ï¿½), Î˜ = Î˜(ğ‘Ÿï¿½ï¿½ï¿½), Î¦ = Î¦(ğ‘Ÿï¿½ï¿½ï¿½); STOP 10: end if 11: end forInitialized scheme of ğš¯ . In the algorithm BCSBM, the initialization of the probability matrix Î˜ has a great influence on the convergence speed of the algorithm. When the network structure generated by the initialization of the stochastic block probability matrix Î˜ is consistent with the real network structure, the algorithm will converge quickly. However, when the initial network structure (i.e., the initial values of Î˜ ) is inconsistent with the real network structure, the algorithm will converge very slowly. For the algorithm to achieve stability with as few iterations as possible, we apply maximum entropy distribution [33] and maximum likelihood to make appropriate choices for the stochastic block probability matrix Î˜ . The specific approach is as follows [22]. The initialization of the stochastic block probability matrix Î˜ is divided into three schemes: (1) when the diagonal elements are larger than the non-diagonal elements, it corresponds to the assortative structures in network; (2) when the diagonal elements are smaller than the non-diagonal elements, it corresponds to disassortative structures in network; and (3) when the elements in Î˜ are floating around a certain value (e.g., 0.5), it corresponds to the other structures in network. The BCSBM algorithm is executed a number of times (e.g., 10 times) for each of these three cases, and then the average of the maximum likelihoods is calculated for each scheme. The initialization form of Î˜ corresponding to the scheme with the largest average is used as the initialization of the BCSBM algorithm. The time complexity of BCSBM algorithm mainly depends on E-step and M-step of the EM algorithm for parameters estimation. In each iteration process, the time complexity of E-step is ÎŸ(ğ‘–ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½2 + ğ‘–ï¿½ï¿½ï¿½ğ¾ğ‘ï¿½ï¿½ï¿½), and the time complexity of M-step is ÎŸ(ğ‘–ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ + ğ‘ï¿½ï¿½ï¿½2 + ğ‘–ï¿½ï¿½ï¿½ğ¾ğ‘ï¿½ï¿½ï¿½). Since the number of communities ğ‘ï¿½ï¿½ï¿½ is much smaller than the number of nodes ğ‘–ï¿½ï¿½ï¿½ , i.e., ğ‘ï¿½ï¿½ï¿½ â‰ª ğ‘–ï¿½ï¿½ï¿½ . Therefore, the time complexity of M-step can be written as ÎŸ(ğ‘–ï¿½ï¿½ï¿½ğ¾ğ‘ï¿½ï¿½ï¿½) , and due to the maximum number of iterations of the algorithm is ğ¼ğ‘‡ , the overall time complexity of the algorithm is ÎŸ(ğ¼ğ‘‡(ğ‘–ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½2 + ğ‘–ï¿½ï¿½ï¿½ğ¾ğ‘ï¿½ï¿½ï¿½)). 4. Community detection based on BCSBM model Since the node-community memberships matrix ğ· characterizes the distribution of each node over all communities, our main goal is to infer the node-community memberships matrix ğ· = (ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ)ğ‘–ï¿½ï¿½ï¿½Ã—ğ‘ï¿½ï¿½ï¿½ , i.e., the probability that a node belongs to any community ğ‘‰ğ‘Ÿ(ğ‘ï¿½ï¿½ï¿½ = 1, 2, â‹¯ , ğ‘ï¿½ï¿½ï¿½). We infer the node-community memberships in network by hard division, that is, using ğ‘ï¿½ï¿½ï¿½âˆ— = argmax ğ‘Ÿ {ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ} to limit that a node can only belong to a community. Since hidden variables are introduced when the model parameters are inferred by the EM algorithm, ğ· = (ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ)ğ‘–ï¿½ï¿½ï¿½Ã—ğ‘ï¿½ï¿½ï¿½ cannot be processed directly. In order to get the hard partition, we set an operation on the parameter ğ· = (ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ)ğ‘–ï¿½ï¿½ï¿½Ã—ğ‘ï¿½ï¿½ï¿½, Î˜ = (ğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½)ğ‘ï¿½ï¿½ï¿½Ã—ğ‘ï¿½ï¿½ï¿½, that is ğ¼ğ‘–ğ‘Ÿ = âˆ‘ ğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿï¿½ï¿½ï¿½=1 âˆ‘ ğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ,ğ‘Ÿï¿½ï¿½ï¿½=1 (10) The BCSBM algorithm can use ğ‘ï¿½ï¿½ï¿½âˆ— = argmax ğ‘Ÿ {ğ¼ğ‘–ğ‘Ÿ} to find which community the nodeultimately belongs to. 5. Experimental results and analysis 5.1 Datasets In this paper, six real-world attributed networks are selected to examine the community detection performance of BCSBM model, including WebKB (Cornell, Texas, Washington, Wisconsin), Cora and Citeceer. The basic characteristics of the attributed networks are shown in Table 1, where ğ‘–ï¿½ï¿½ï¿½ and ğ‘–ï¿½ï¿½ï¿½ are the number of nodes and links, respectively; ğ¾ is the attribute type; and ğ‘ï¿½ï¿½ï¿½ is the number of communities. Table 1 Features of the attributed Networks Datasets n m K c Structure WebKB Cornell 195 304 1703 5 disassortative Texas 187 328 1703 5 disassortative Washington 230 446 1703 5 disassortative Wisconsin 265 530 1703 5 disassortative Cora â€” 2708 5429 1433 7 assortative Citeseer â€” 3312 4723 3703 6 assortative 1) WebKB dataset [34] is a citation network consisting of web pages and links between web pages of four American universities, Cornell, Texas, Washington, and Wisconsin, with a total of 877 nodes representing all web pages, and 1,608 links representing hyperlinks between web pages. Web pages (i.e., nodes) in network are classified into the following five types, i.e., course, faculty, student, project, and staff. Each node consists of a 1703-dimensional attribute vector. 2) Cora dataset [35] is a citation network of scientific and technical literature with 2708 nodes representing all scientific publications. 5429 links representing the citation relationships from a publication to another. All the scientific publications (i.e., nodes) in network are classified into the following seven types, i.e., case-based reasoning, genetic algorithms, neural networks, probabilistic methods, reinforcement learning, rule learning, and theory. Each node consists of a 1433- dimensional attribute vector. 3) Citeseer dataset [36] is an academic citation network containing 3312 nodes representing all academic papers. 4723 links representing citation relationships between papers. All papers (i.e., nodes) in network are classified into the following six types, i.e., agents, artificial intelligence, databases, human-computer interaction, information retrieval, and machine learning. Each node consists of a 3703- dimensional attribute vector. 5.2 Evaluation criteria To evaluate the community detection performance of BCSBM model on the realnetworks, two evaluation indexes, Normalized Mutual Information (NMI) and Pairwise F-measure (PWF), are adopted in this paper. (1) ğ¾ï¿½ï¿½ï¿½ğ¾ï¿½ï¿½ï¿½ğ¼ The ğ¾ï¿½ï¿½ï¿½ğ¾ï¿½ï¿½ï¿½ğ¼ proposed in [37] is based on the confusion matrix to judge the completeness of information retention after community division. Its definition is shown in Eq. (11). ğ¾ï¿½ï¿½ï¿½ğ¾ï¿½ï¿½ï¿½ğ¼(ğ´, ğ´ï¿½ï¿½ï¿½) = âˆ’2 âˆ‘ âˆ‘ ğ¾ï¿½ï¿½ï¿½ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½log (ğ¾ï¿½ï¿½ï¿½ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ğ¾ï¿½ï¿½ï¿½ ğ¾ï¿½ï¿½ï¿½ğ‘Ÿğ¾ï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½) ğ‘ï¿½ï¿½ï¿½2 ğ‘Ÿï¿½ï¿½ï¿½=1 ğ‘ï¿½ï¿½ï¿½1 ğ‘Ÿ=1 âˆ‘ ğ¾ï¿½ï¿½ï¿½ğ‘Ÿ ğ‘ï¿½ï¿½ï¿½1 ğ‘Ÿ=1 log (ğ¾ï¿½ï¿½ï¿½ğ‘Ÿ ğ¾ï¿½ï¿½ï¿½ ) + âˆ‘ ğ¾ï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½ ğ‘ï¿½ï¿½ï¿½2 ğ‘Ÿï¿½ï¿½ï¿½=1 log (ğ¾ï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½ ğ¾ï¿½ï¿½ï¿½ ) (11) Where ğ´ is real community, ğ´ï¿½ï¿½ï¿½ is the community divided by the community detection algorithm, ğ‘ï¿½ï¿½ï¿½1 denotes the number of real community ğ´, ğ‘ï¿½ï¿½ï¿½2 denotes the number of community ğ´ï¿½ï¿½ï¿½ divided by the community detection algorithm, ğ¾ï¿½ï¿½ï¿½ is the total number of nodes in network ğ·ï¿½ï¿½ï¿½, ğ¾ï¿½ï¿½ï¿½ğ‘Ÿ, ğ¾ï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½ denote the number of nodes in communities ğ‘ï¿½ï¿½ï¿½ and ğ‘ï¿½ï¿½ï¿½ respectively, ğ¾ï¿½ï¿½ï¿½ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ denotes the number of nodes that should belong to community ğ‘ï¿½ï¿½ï¿½ but are wrongly assigned to community ğ‘ï¿½ï¿½ï¿½. The range of ğ¾ï¿½ï¿½ï¿½ğ¾ï¿½ï¿½ï¿½ğ¼ is [0,1] , the larger the value of ğ¾ï¿½ï¿½ï¿½ğ¾ï¿½ï¿½ï¿½ğ¼ is, the better the community detection performance. If ğ´ = ğ´ï¿½ï¿½ï¿½, ğ¾ï¿½ï¿½ï¿½ğ¾ï¿½ï¿½ï¿½ğ¼(ğ´, ğ´ï¿½ï¿½ï¿½) = 1 . If ğ´ and ğ´ï¿½ï¿½ï¿½ are completely different, ğ¾ï¿½ï¿½ï¿½ğ¾ï¿½ï¿½ï¿½ğ¼(ğ´, ğ´ï¿½ï¿½ï¿½) = 0. (2) ğ‘ƒğ‘‰ï¿½ï¿½ï¿½ğ·ï¿½ï¿½ï¿½ The ğ‘ƒğ‘‰ï¿½ï¿½ï¿½ğ·ï¿½ï¿½ï¿½ proposed in [38] integrates the concepts of precision and recall into a single evaluation, and its definition is shown in Eq. (12). ğ‘ƒğ‘‰ï¿½ï¿½ï¿½ğ·ï¿½ï¿½ï¿½ = 2 Ã— ğ‘ƒğ‘ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ Ã— ğ‘…ğ‘ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘ğ‘–ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ ğ‘ƒğ‘ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ Ã— ğ‘…ğ‘ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘ğ‘–ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ (12) where ğ‘ƒğ‘ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ = |ğ‘…ï¿½ï¿½ï¿½ âˆ© ğ‘…ï¿½ï¿½ï¿½|/|ğ‘…ï¿½ï¿½ï¿½| , ğ‘…ğ‘ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘ğ‘–ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ = |ğ‘…ï¿½ï¿½ï¿½ âˆ© ğ‘…ï¿½ï¿½ï¿½|/|ğ‘…ï¿½ï¿½ï¿½| denote the precision and recall of the division results of the community detection algorithm, respectively, ğ‘…ï¿½ï¿½ï¿½ denotes the set of nodes that are assigned to the same community, ğ‘…ï¿½ï¿½ï¿½ denotes the set of nodes that have the same label, and | âˆ™ | denotes the number of elements in the set. The range of values of ğ‘ƒğ‘‰ï¿½ï¿½ï¿½ğ·ï¿½ï¿½ï¿½ is also [0,1] . The larger the value of ğ‘ƒğ‘‰ï¿½ï¿½ï¿½ğ·ï¿½ï¿½ï¿½ is, the better the partitioning effect of community algorithm division. 5.3 Experimental results and analysis To verify the validity of the BCSBM model, in this section, experiments are conducted on the six real-world attributed networks shown in Table 1 and compared with the existing generative models that integrate links and attributes of nodes, PPSB_DC [19], BNPA [23], NEMBP [25], PSB_PG [22], and DPSB_PG [30]. In order to maintain fairness, all algorithms keep the optimal parameter settings mentioned in the original paper, and the experimental results are shown in Table 2 and Table 3, Fig.3 and Fig.4. Table 2 and Fig.3 show the ğ¾ï¿½ï¿½ï¿½ğ¾ï¿½ï¿½ï¿½ğ¼ metrics of the six algorithms, and Table 3 and Fig.4 show the ğ‘ƒğ‘‰ï¿½ï¿½ï¿½ğ·ï¿½ï¿½ï¿½ metrics of the six algorithms. Since the EM algorithm is particularly sensitive to initial values, we conducted 30 experiments on each model, and the mean and maximum values of 30 times are given for two indicators.Table 2 ğ¾ï¿½ï¿½ï¿½ğ¾ï¿½ï¿½ï¿½ğ¼ of the BCSBM model and compared algorithms on attributed networks Datasets NMI Model Value PPSB_DC BNPA NEMBP PSB_PG DPSB_PG BCSBM Cornell mean 0.1128 0.0772 0.1510 0.3131 0.3246 0.3550 max 0.2503 0.0933 0.2793 0.3973 0.4460 0.4555 Texas mean 0.2085 0.2265 0.2965 0.2882 0.2926 0.3214 max 0.3663 0.2694 0.4202 0.3750 0.3933 0.4636 Washington mean 0.1726 0.2469 0.1938 0.3235 0.3222 0.3617 max 0.3690 0.2701 0.3107 0.3631 0.3437 0.4106 Wisconsin mean 0.1315 0.3212 0.2322 0.3736 0.3772 0.4219 max 0.2409 0.3413 0.4075 0.4230 0.4436 0.4787 Cora mean 0.1820 0.4391 0.4033 0.3012 0.3143 0.3360 max 0.5221 0.5022 0.4757 0.3699 0.3488 0.3593 Citeseer mean 0.1335 0.1700 0.2003 0.2507 0.2646 0.3045 max 0.3805 0.3196 0.2911 0.3318 0.3246 0.3862 Table 3 ğ‘ƒğ‘‰ï¿½ï¿½ï¿½ğ·ï¿½ï¿½ï¿½ of the BCSBM model and compared algorithms on attributed networks Datasets PWF Model Value PPSB_DC BNPA NEMBP PSB_PG DPSB_PG BCSBM Cornell mean 0.3789 0.3446 0.3646 0.4378 0.4498 0.4882 max 0.5025 0.3528 0.4722 0.5672 0.6179 0.6637 Texas mean 0.5610 0.5084 0.5622 0.4117 0.4250 0.4852 max 0.6753 0.5257 0.7002 0.5028 0.5408 0.5854 Washington mean 0.4751 0.3851 0.4034 0.4879 0.4829 0.5233 max 0.6118 0.3921 0.6064 0.5483 0.5123 0.6175 Wisconsin mean 0.3900 0.4818 0.3867 0.5290 0.5294 0.5916 max 0.4839 0.4967 0.5484 0.5880 0.5953 0.6501 Cora mean 0.2835 0.4809 0.4337 0.3554 0.3621 0.3846 max 0.3592 0.5423 0.5203 0.4228 0.3891 0.4073 Citeseer mean 0.2733 0.3548 0.3236 0.3561 0.3642 0.4014 max 0.4768 0.3984 0.3804 0.4323 0.3977 0.4318 Note 1: The red bolded values in Table 2 and Table 3 indicate the best, and the black bolded values indicate the next best of the six models. Note 2: The first 3 columns of data are from the literature [30].Fig.3 ğ¾ï¿½ï¿½ï¿½ğ¾ï¿½ï¿½ï¿½ğ¼ of the six algorithms on attributed networks Fig.4 ğ‘ƒğ‘‰ï¿½ï¿½ï¿½ğ·ï¿½ï¿½ï¿½ of the six algorithms on attributed networks From the above experimental results, it can be seen that the BCSBM model proposed in this paper is suitable for a variety of network structures detection, and the detection effect is significantly improved in the real attribute networks (Cornell, Texas, Washington, Wisconsin) containing disassortative structures. Compared with the PSB_PG model without considering the degree of nodes, the DPSB_PG model has improved the detection effect on attributed networks Cornell, Texas, and Wisconsin, Cornell Texas Washington Wisconsin Cora Citeseer 0.0 0.1 0.2 0.3 0.4 0.5 NMI Datasets PPSB_DC BNPA NEMBP PSB_PG DPSB_PG BCSBM Cornell Texas Washington Wisconsin Cora Citeseer 0.0 0.1 0.2 0.3 0.4 0.5 0.6 PWF Datasets PPSB_DC BNPA NEMBP PSB_PG DPSB_PG BCSBMbut the performance on the Washington is slightly worse. However, the BCSBM model proposed in this paper takes into account the betweenness centrality and clustering coefficient of nodes at the same time, and performs best on the four real attribute networks with disassortative structures. The experiments show that the integration betweenness centrality and clustering coefficient of nodes have a positive impact on the community detection for attributed networks. The BNPA model performs best on the attributed network Cora containing assortative structure, this is due to the fact that it introduces a priori information, which needs to adjust priori parameters, and its detection precision depends on the accuracy of the number of communities estimated, which does not perform well in other networks. The model BCSBM proposed in this paper performs best on the attributed network Citeseer with assortative structure, which indicates that the BCSBM model has good performance in attributed networks containing disassortative and assortative structures. In summary, the comprehensive performance of the BCSBM model proposed in this paper is better than the other five related algorithms, and the experiments show that the stochastic block model integrating betweenness centrality and clustering coefficient of nodes, as well as the Poisson distribution can better identify the assortative and disassortative structures in attributed networks. 6. Conclusion and discussion Integrating the linking relationships between nodes and the inherent attribute information of the nodes to mine the potential structure in network, and utilizing the attribute information to enhance the interpretability of the identified community, and then revealing the function of the network system is gradually being paid attention to. Based on the DPSB_PG model, the stochastic block model BCSBM that integrating betweenness centrality and clustering coefficient of nodes in attributed networks is proposed in this paper. The BCSBM model combines the network topology information and attribute information, and improves the accuracy of community detection by fitting the real network from the perspectives of node importance and node neighborhood. The uniform form of Poisson distribution facilitates the estimation of model parameters, and the EM algorithm is used to realize the parameters inference to ensure the convergence of the model. By comparing with the existing model on real attribute networks, it can be seen that BCSBM model can discover a variety of structures in networks, and the community detection accuracy is better than the DPSB_PG model, and the performance is improved in different extent compared with other existing related algorithms, which further illustrates the importance of betweenness centrality and clustering coefficient of nodes to improve the accuracy of community detection algorithm. Since the EM algorithm may require a large amount of computation and high time complexity in the process of parameters estimation depending on the network size, it affects the efficiency of the model. Therefore, in future work, other parameter estimation methods can be considered to improve the computational efficiency of the algorithm while ensuring the accuracy of community detection.Acknowledgment This work is supported by the National Natural Science Foundation of China [grant number 61976176]. Appendix A From Eq. (5), we know that the lower bound of the log-likelihood function is ğ¾ï¿½ï¿½ï¿½Ì…(ğ·, Î˜, Î¦) = 1 2 âˆ‘ âˆ‘ [ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ ln (ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ğ›¾ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½ ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ ) âˆ’ ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ğ›¾ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½] ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ,ğ‘Ÿï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–,ğ‘–ï¿½ï¿½ï¿½=1 + âˆ‘ âˆ‘ âˆ‘ [ğ‘¥ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ ln (ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½ ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ ) âˆ’ ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½] ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ=1 ğ¾ ğ‘–ï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–=1 (5) Under ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ = ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ and âˆ‘ ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ = âˆ‘ ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ = 1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–=1 , we have ğ¾ï¿½ï¿½ï¿½Ìƒ(ğ·) = 1 2 âˆ‘ âˆ‘ [ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ ln (ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ğ›¾ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½ ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ ) âˆ’ ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½] ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ,ğ‘Ÿï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–,ğ‘–ï¿½ï¿½ï¿½=1 + âˆ‘ âˆ‘ âˆ‘ [ğ‘¥ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ ln (ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½ ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ ) âˆ’ ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½] + âˆ‘ ğœğ‘Ÿ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ=1 ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ=1 ğ¾ ğ‘–ï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–=1 (1 âˆ’ âˆ‘ ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ ğ‘–ï¿½ï¿½ï¿½ ğ‘–=1 ) (A1) Taking the partial derivative of ğ¾ï¿½ï¿½ï¿½Ìƒ(ğ·), we have ğœ•ğ¾ï¿½ï¿½ï¿½Ìƒ(ğ·) ğœ•ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ = 1 2 âˆ‘ âˆ‘ ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–ï¿½ï¿½ï¿½=1 ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ âˆ’ 1 2 âˆ‘ âˆ‘ ğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½ + âˆ‘ ğ‘¥ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ ğ¾ ğ‘–ï¿½ï¿½ï¿½=1 ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–ï¿½ï¿½ï¿½=1 âˆ’ âˆ‘ ğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½ âˆ’ ğœğ‘Ÿ ğ¾ ğ‘–ï¿½ï¿½ï¿½=1 = 1 2 âˆ‘ âˆ‘ ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–ï¿½ï¿½ï¿½=1 ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ âˆ’ 1 2 âˆ‘ ğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ,ğ‘Ÿï¿½ï¿½ï¿½=1 + âˆ‘ ğ‘¥ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ ğ¾ ğ‘–ï¿½ï¿½ï¿½=1 ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ âˆ’ 1 âˆ’ ğœğ‘Ÿ (A2) Let ğœ•ğ¾ï¿½ï¿½ï¿½Ìƒ(ğ·) ğœ•ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ = 0, then 1 2 âˆ‘ âˆ‘ ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–ï¿½ï¿½ï¿½=1 ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ âˆ’ 1 2 âˆ‘ ğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ,ğ‘Ÿï¿½ï¿½ï¿½=1 + âˆ‘ ğ‘¥ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ ğ¾ ğ‘–ï¿½ï¿½ï¿½=1 ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ âˆ’ 1 âˆ’ ğœğ‘Ÿ = 0 (A3) 1 2 âˆ‘ âˆ‘ ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–,ğ‘–ï¿½ï¿½ï¿½=1 âˆ’ 1 2 âˆ‘ ğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ,ğ‘Ÿï¿½ï¿½ï¿½=1 + âˆ‘ âˆ‘ ğ‘¥ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ ğ¾ ğ‘–ï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–=1 âˆ’ 1 âˆ’ ğœğ‘Ÿ = 0 (A4) By Eq. (A3), Eq.(A4) and ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ = (ğ‘–ï¿½ï¿½ï¿½ğ‘– + ğ‘ï¿½ï¿½ï¿½ğ‘– + ğ‘ï¿½ï¿½ï¿½ğ‘–)ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ , we have ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ in Eq. (8) as follows.ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ = âˆ‘ âˆ‘ ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ + 2 Ã— âˆ‘ ğ‘¥ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ ğ¾ ğ‘–ï¿½ï¿½ï¿½=1 ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–ï¿½ï¿½ï¿½=1 (ğ‘–ï¿½ï¿½ï¿½ğ‘– + ğ‘ï¿½ï¿½ï¿½ğ‘– + ğ‘ï¿½ï¿½ï¿½ğ‘–) Ã— [âˆ‘ âˆ‘ ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ + 2 Ã— âˆ‘ âˆ‘ ğ‘¥ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ ğ¾ ğ‘–ï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–=1 ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–,ğ‘–ï¿½ï¿½ï¿½=1 ] Note the constraint âˆ‘ ğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ,ğ‘Ÿï¿½ï¿½ï¿½=1 = 1, we have ğ¾ï¿½ï¿½ï¿½Ìƒ(Î˜) = 1 2 âˆ‘ âˆ‘ [ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ ln (ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ğ›¾ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½ ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ ) âˆ’ ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ğ›¾ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½] ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ,ğ‘Ÿï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–,ğ‘–ï¿½ï¿½ï¿½=1 + âˆ‘ âˆ‘ âˆ‘ [ğ‘¥ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ ln (ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½ ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ ) âˆ’ ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½] + ğœ‡ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ=1 ğ¾ ğ‘–ï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–=1 (1 âˆ’ âˆ‘ ğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ,ğ‘Ÿï¿½ï¿½ï¿½=1 ) (A5) Taking the partial derivative of ğ¾ï¿½ï¿½ï¿½Ìƒ(Î˜), we have ğœ•ğ¾ï¿½ï¿½ï¿½Ìƒ(Î˜) ğœ•ğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ = 1 2 âˆ‘ ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ ğ‘–ï¿½ï¿½ï¿½ ğ‘–,ğ‘–ï¿½ï¿½ï¿½=1 ğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ âˆ’ 1 2 âˆ‘ ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğ›¾ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½ ğ‘–ï¿½ï¿½ï¿½ ğ‘–,ğ‘–ï¿½ï¿½ï¿½=1 âˆ’ ğœ‡ = 1 2 âˆ‘ ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ ğ‘–ï¿½ï¿½ï¿½ ğ‘–,ğ‘–ï¿½ï¿½ï¿½=1 ğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ âˆ’ 1 2 âˆ’ ğœ‡ (A6) Let ğœ•ğ¾ï¿½ï¿½ï¿½Ìƒ(Î˜) ğœ•ğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ = 0, then 1 2 âˆ‘ ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ ğ‘–ï¿½ï¿½ï¿½ ğ‘–,ğ‘–ï¿½ï¿½ï¿½=1 ğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ âˆ’ 1 2 âˆ’ ğœ‡ = 0 (A7) âˆ‘ âˆ‘ ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ,ğ‘Ÿï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–.ğ‘–ï¿½ï¿½ï¿½=1 âˆ’ 1 âˆ’ 2ğœ‡ = 0 (A8) By Eq. (A7) and Eq.(A8), we can derive the equation ğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ in Eq. (9) as follows. ğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ = âˆ‘ ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ ğ‘–ï¿½ï¿½ï¿½ ğ‘–,ğ‘–ï¿½ï¿½ï¿½=1 âˆ‘ âˆ‘ ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ,ğ‘Ÿï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–,ğ‘–ï¿½ï¿½ï¿½=1 Similarly, for ğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½, we have ğ¾ï¿½ï¿½ï¿½Ìƒ(Î¦) = 1 2 âˆ‘ âˆ‘ [ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ ln (ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ğ›¾ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½ ğ‘ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ ) âˆ’ ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœƒğ‘Ÿğ‘Ÿï¿½ï¿½ï¿½ğ›¾ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘ï¿½ï¿½ï¿½ğ‘–ï¿½ï¿½ï¿½ğ‘Ÿï¿½ï¿½ï¿½] ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ,ğ‘Ÿï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–,ğ‘–ï¿½ï¿½ï¿½=1 + âˆ‘ âˆ‘ âˆ‘ [ğ‘¥ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ ln (ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½ ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ ) âˆ’ ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½] + âˆ‘ ğœ‰ğ‘Ÿ ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ=1 ğ‘ï¿½ï¿½ï¿½ ğ‘Ÿ=1 ğ¾ ğ‘–ï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–=1 (1 âˆ’ âˆ‘ ğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½ ğ¾ ğ‘–ï¿½ï¿½ï¿½=1 ) (A9)ğœ•ğ¾ï¿½ï¿½ï¿½Ìƒ(Î¦) ğœ•ğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½ = âˆ‘ ğ‘¥ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ ğ‘–ï¿½ï¿½ï¿½ ğ‘–=1 ğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½ âˆ’ âˆ‘ ğ›¾ï¿½ï¿½ï¿½ğ‘–ğ‘ï¿½ï¿½ï¿½ğ‘–ğ‘Ÿ ğ‘–ï¿½ï¿½ï¿½ ğ‘–=1 âˆ’ ğœ‰ğ‘Ÿ = âˆ‘ ğ‘¥ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ ğ‘–ï¿½ï¿½ï¿½ ğ‘–=1 ğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½ âˆ’ 1 âˆ’ ğœ‰ğ‘Ÿ (A10) Let ğœ•ğ¾ï¿½ï¿½ï¿½Ìƒ(Î¦) ğœ•âˆ…ğ‘Ÿğ‘–ï¿½ï¿½ï¿½ = 0, then âˆ‘ ğ‘¥ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ ğ‘–ï¿½ï¿½ï¿½ ğ‘–=1 ğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½ âˆ’ 1 âˆ’ ğœ‰ğ‘Ÿ = 0 (A11) âˆ‘ âˆ‘ ğ‘¥ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ ğ¾ ğ‘–ï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–=1 âˆ’ 1 âˆ’ ğœ‰ğ‘Ÿ = 0 (A12) By Eq. (A11) and Eq.(A12), we have ğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½ in Eq. (9) in the following. ğœ™ğ‘Ÿğ‘–ï¿½ï¿½ï¿½ = âˆ‘ ğ‘¥ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ ğ‘–ï¿½ï¿½ï¿½ ğ‘–=1 âˆ‘ âˆ‘ ğ‘¥ğ‘–ğ‘–ï¿½ï¿½ï¿½ğ›¾ğ‘–ğ‘–ï¿½ï¿½ï¿½ ğ‘Ÿ ğ¾ ğ‘–ï¿½ï¿½ï¿½=1 ğ‘–ï¿½ï¿½ï¿½ ğ‘–=1 References [1] Bothorel C, Cruz J D, Magnani M, et al. Clustering attributed graphs: models, measures and methods[J]. Network Science, 2015, 3(3): 408-444. [2] Khan K U, Nawaz W, Lee Y K. Set-based unified approach for summarization of a multi- attributed graph[J]. World Wide Web, 2017, 20: 543-570. [3] Wang Y, Li Y, Fan J, et al. A survey of typical attributed graph queries[J]. World Wide Web, 2021, 24: 297-346. [4] Zhou Y, Cheng H, Yu J X. Graph clustering based on structural/attribute similarities[J]. Proceedings of the VLDB Endowment, 2009, 2(1): 718-729. [5] Chen X, Peng H, Hu J. K-medoids substitution clustering method and a new clustering validity index method[C]. Sixth World Congress on Intelligent Control and Automation. IEEE, 2006, 2: 5896-5900. [6] Z. Wu, L. Zhao, S.-Y. Ho. Community Detection with Topological Structure and Attributesin Information Networks[J]. ACM Transactions on Intelligent Systems and Technology, 2017,8(2):1â€“17. [7] Alinezhad E, Teimourpour B, Sepehri M M, et al. Community detection in attributed networks considering both structural and attribute similarities: two mathematical programming approaches[J]. Neural Computing and Applications, 2020, 32: 3203-3220. [8] Falih I, Grozavu N, Kanawati R, et al. ANCA: Attributed network clustering algorithm[C]. International Conference on Complex Networks and their Applications. Springer, Cham, 2017: 241-252. [9] Berahmand K, Haghani S, Rostami M, et al. A new attributed graph clustering by using label propagation in complex networks[J]. Journal of King Saud University-Computer and Information Sciences, 2022, 34(5): 1869-1883. [10] Wang X, Jin D, Cao X, et al. Semantic community identification in large attribute networks[C].Proceedings of the AAAI Conference on Artificial Intelligence. 2016, 30(1). [11] Akoglu L, Tong H, Meeder B, et al. Pics: Parameter-free identification of cohesive subgroups in large attributed graphs[C]. Proceedings of the 2012 SIAM international conference on data mining. Society for Industrial and Applied Mathematics, 2012: 439-450. [12] Li Z, Pan Z, Hu G, et al. Detecting semantic communities in social networks[J]. IEICE TRANSACTIONS on Fundamentals of Electronics, Communications and Computer Sciences, 2017, 100(11): 2507-2512. [13] Huang J, Zhang T, Yu W, et al. Community Detection Based on Modularized Deep Nonnegative Matrix Factorization[J]. International Journal of Pattern Recognition and Artificial Intelligence, 2021, 35(2): 2159006. [14] Yang S, Yang B. Enhanced network embedding with text information[C].24th International Conference on Pattern Recognition (ICPR). IEEE, 2018: 326-331. [15] Newman M E J, Clauset A. Structure and inference in annotated networks[J]. Nature communications, 2016, 7(1): 11863. [16] Fortunato S, Hric D. Community detection in networks: A user guide[J]. Physics reports, 2016, 659: 1-44. [17] Liu X, Yang B, Song W, et al. A block-based generative model for attributed network embedding[J]. World Wide Web, 2021, 24: 1439-1464. [18] Holland P W, Laskey K B, Leinhardt S. Stochastic blockmodels: First steps[J]. Social Networks, 1983, 5(2): 109-137. [19] Chai B, Yu J, Jia C, et al. Combining a popularity-productivity stochastic block model with a discriminative-content model for general structure detection[J]. Physical review E, 2013, 88(1): 012807. [20] Shen H W, Cheng X Q, Guo J F. Exploring the structural regularities in networks[J]. Physical Review E, 2011, 84(5): 056111. [21] Yang T, Chi Y, Zhu S, et al. Directed network community detection: A popularity and productivity link model[C]. Proceedings of the 2010 SIAM international conference on data mining. Society for Industrial and Applied Mathematics, 2010: 742-753. [22] Chang Z, Jia C, Yin X, et al. A generative model for exploring structure regularities in attributed networks[J]. Information Sciences, 2019, 505: 252-264. [23] Chen Y, Wang X, Bu J, et al. Network structure exploration in networks with node attributes[J]. Physica A: Statistical Mechanics and its Applications, 2016, 449: 240-253. [24] Newman M E J, Leicht E A. Mixture models and exploratory analysis in networks[J]. Proceedings of the National Academy of Sciences, 2007, 104(23): 9564-9569. [25] He D, Feng Z, Jin D, et al. Joint identification of network communities and semantics via integrative modeling of network topologies and node contents[C]. Proceedings of the AAAI Conference on Artificial Intelligence. 2017, 31(1). [26] Karrer B, Newman M E J. Stochastic block models and community structure in networks[J]. Physical review E, 2011, 83(1): 016107. [27] Dempster A P, Laird N M, Rubin D B. Maximum likelihood from incomplete data via the EM algorithm[J]. Journal of the royal statistical society: series B (methodological), 1977, 39(1): 1- 22. [28] Decelle A, Krzakala F, Moore C, et al. Inference and phase transitions in the detection ofmodules in sparse networks[J]. Physical Review Letters, 2011, 107(6): 065701. [29] Chen H, Yu Z, Yang Q, et al. Attributed graph clustering with subspace stochastic block model[J]. Information Sciences, 2020, 535: 130-141. [30] Zheng Yimei, Jia Caiyan, Chang Zhenhai, Li Xuanya. A Degree Corrected Stochastic Block Model for Attributed Networks[J]. Journal of Computer Research and Development, 2020, 57(8): 1650-1662. doi: 10.7544/issn1000-1239.2020.20200158 [31] Zhou M, Han Q, Li M, et al. Nearest neighbor walk network embedding for link prediction in complex networks[J]. Physica A: Statistical Mechanics and its Applications, 2023, 620: 128757. [32] Wang Z Y, Han J T, Zhao J. Identifying node spreading influence for tunable clustering coefficient networks[J]. Physica A: Statistical Mechanics and its Applications, 2017, 486: 242- 250. [33] Xuan G, Shi Y Q, Chai P, et al. An enhanced EM algorithm using maximum entropy distribution as initial condition[C]. Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012). IEEE, 2012: 849-852. [34] Sen P, Namata G, Bilgic M, et al. Collective classification in network data[J]. AI magazine, 2008, 29(3): 93-93. [35] Rostami M, Oussalah M. A novel attributed community detection by integration of feature weighting and node centrality[J]. Online Social Networks and Media, 2022, 30: 100219. [36] Namata G, London B, Getoor L, et al. Query-driven active surveying for collective classification[C].10th international workshop on mining and learning with graphs. 2012, 8: 1. [37] Danon L, Diaz-Guilera A, Duch J, et al. Comparing community structure identification[J]. Journal of statistical mechanics: Theory and experiment, 2005(09): P09008. [38] Yang T, Jin R, Chi Y, et al. Combining link and content for community detection: a discriminative approach[C]. Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining. 2009: 927-936. [39] Liu W, Chang Z, Jia C, et al. A generative node-attribute network model for detecting generalized structure and semantics[J]. Physica A: Statistical Mechanics and its Applications, 2022, 588: 126557.