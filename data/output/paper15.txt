1 Least Squares Maximum and Weighted Generalization-Memorization Machines Shuai Wang, Zhen Wang and Yuan-Hai Shao∗ Abstract—In this paper, we propose a new way of remembering by introducing a memory influence mechanism for the least squares support vector machine (LSSVM). Without changing the equation constraints of the original LSSVM, this mechanism, allows an accurate partitioning of the training set without over- fitting. The maximum memory impact model (MIMM) and the weighted impact memory model (WIMM) are then proposed. It is demonstrated that these models can be degraded to the LSSVM. Furthermore, we propose some different memory impact func- tions for the MIMM and WIMM. The experimental results show that that our MIMM and WIMM have better generalization performance compared to the LSSVM and significant advantage in time cost compared to other memory models. Index Terms—Generalization-memorization mechanism, Ker- nel, Support vector machine, Kernel functiontypesetting. I. INTRODUCTION Z ERO experience risk, also known as memory of training data, has been widely researched and discussed in ma- chine learning [1]–[3]. Traditional learning machines require to classify the training samples correctly as much as possible, but it is prone to fall into the overfitting problem. Therefore, to avoid overfitting, we commonly use regularization techniques but also reduce the memory ability, e.g.support vector ma- chines (SVMs) [4]. However, more powerful tools have been proposed in machine learning based on the zero empirical risks. For instance, Deep Neural Network (DNN) [1], [5], [6] has a structure of multiple hidden layers. Each neuron receives inputs from the neurons in the previous layer and generates outputs that serve as inputs to the neurons in the next layer. And each hidden layer contains multiple neurons to achieve the almost zero empirical risk. It is also realized by Recurrent Neural Network (RNN) [7]–[10] which is a neural network model commonly used in sequential data processing. Compared to traditional feed-forward neural networks, RNN considers temporal dependencies when processing sequential data. Information is allowed to be passed from the current time step to the next time step. This recurrent structure allows RNN to process sequence inputs of arbitrary length and to capture temporal dependencies in the sequence. The Long Short-Term Memory (LSTM) [11]–[13] is a particular RNN for solving the long-term dependency problem in RNN. Unlike the traditional RNN, the LSTM model introduces three gates (input gate, S. Wang is with the School of Mathematics and Statistics, Hainan University , Haikou, China. (e-mail: wangshuai282615@163.com). Z. Wang is with the School of Mathematical Sciences, Inner Mongolia University, Hohhot, 010021, P.R. China. (e-mail: wangzhen@imu.edu.cn). Y.H. Shao (*Corresponding author) is with the Management School, Hainan University, Haikou, P.R. China. (e-mail:shaoyuanhai21@163.com). Manuscript received xx, xx; revised xx, xx. forget gate and output gate) and a memory unit to effectively capture and remember critical information in long sequences. Unlike the LSTM model of memory, Devansh Arpitet al [5] investigated the role of memory in deep learning, linking it to ability, generalization, and adversarial robustness. It is also shown that the training data itself plays an important role in determining the degree of memory. Zhang et al [14].explored a new mechanism to improve model generalization through explicit memory and proposed the residual memory (ResMem) algorithm, a new approach to augment existing prediction models (e.g., neural networks) by fitting the residuals of the model with k-nearest-neighbor based moderators. Indeed, memory systems have been widely explored by researchers to enhance memorization capabilities in various domains. For instance, in the field of machine learning and ar- tificial intelligence, memory mechanisms have been proposed to assist learners in remembering and revising learning tasks [15]–[17].Rafferty et al. [18] presented an observable Partially Observable Markov Decision Process (POMDP) planning problem to address memory tasks [19], [20], while Settle and Meeder [21] developed a trainable memory retention model that optimizes revision schedules for effective memorization. In the realm of deep reinforcement learning, researchers have explored novel methods and optimal policies, elevating the ef- ficiency and engagement of learners [22]–[24] . In other works related to memory, researchers have focused on statistical char- acteristics of learners’ memory behavior rather than just time- series features [25], [26]. This approach has been extended to consider forgetting mechanisms and spaced repetition to improve memory retention [27], [28]. By transforming the optimization problem into a stochastic shortest path problem, these methods aim to enhance the learning process through efficient memory utilization and forgetting strategies [29]– [31]. Recently, Vapnik and Izmailov [4], [32] studied the memory problem of SVMs and introduced two RBF kernels in the SVMs to improve their memory capability, called SVMm. The two RBF kernels, one for generalization and one for memory, are used to memorize the training samples by properly tuning their parameters to achieve zero empirical risk and have a well generalization performance. Subsequently, a generalization- memorization machine (GMM) [33], [34] presented a more general model and explained the mechanism of SVMm more clearly. In this paper, another new memory mechanism is proposed. It contains two memory models by the least squares sense, i.e., a Maximum Impact Memory Model (MIMM) and a Weighted Impact Memory Model(WIMM). Their learning rate are much arXiv:2308.16456v1 [stat.ML] 31 Aug 20232 faster than the GMM and SVMm,while guaranteeing their zero empirical risks. The main contributions of this paper are as follow: • For the memory problem, we proposed the maximum memory impact (MIMM), which uses only the nearest training points for test point judgments and gives a sufficient condition for the empirical risk of the model to be zero. • For the MIMM model, we constructed a memory influ- ence function suitable for the model to ensure the memory capacity of the model. • We provide a clearer interpretation of the memory kernel of the model and derivatively give conditions for the model to degenerate to LSSVM. • Compared with other memory models, the two memory models we proposed, WIMM and MIMM, are shorter in terms of time cost in memorizing the same learning task machines. The next section provides a brief overview of the development of Support Vector Machines (SVM) and Least Squares Support Vector Machines (LSSVM). It also reviews the GMM models. The third section introduces the new objective function and the novel memory mechanism. This includes discussing memory cost and impact functions and how they contribute to solving the MIMM and WIMM models. The last section presents the numerical experiments conducted to validate the proposed MIMM and WIMM models. Conclusions drawn from these experiments are also discussed in this section II. REVIEW Consider a binary classification problem in a n-dimensional real space Rn. The training set is given by T = {(xi, yi)|i = 1, 2, ..., m}, where xi ∈ Rn is the ith sample, and yi ∈ {+1, −1} is the corresponding label. The training samples and their labels are organized into matrix X∈ Rn×m and diagonal matrix Y with diagonal elements Yii = yi (i = 1, ..., m), respectively. SVM [4], [35], [36] deals with this binary classification problem by finding a pair of parallel hyperplanes in the feature space, where the margin is maximized to separate the two classes as much as possible. Sch¨olkopf et al [37]. proposed a new class of regression and classification models based on the SVM, in which a parameter ν was introduced to not only effectively controls the number of support vectors but also suit for different data distributions well. Twin Support Vector Machine (TWSVM) was introduced by Jayadeva et al. [38]. The TWSVM approach aims to identify a pair of non-parallel hyperplanes that can effectively solve the clas- sification problem, resulting in a reduced problem size com- pared to traditional SVMs. To further accelerate the learning speed of SVMs,the Least Squares Support Vector Machine (LSSVM) [39], [40] was proposed by J.A.K. Suykens et al. Due to the equation constraints in the LSSVM formulation, it requires to solve a system linear equations rather than the quadratic programming problem in the SVM. However, the zero empirical risks are guaranteed in neither of these SVMs. Recently, Vapnik and Izmailov [4], [32], [41] proposed a new kernel function consist of two Gaussian kernels as K(x, x′) = τ exp{−σ2(x− ´x)2}+(1−τ) exp{−σ2 ∗(x− ´x)2} (where 0 ≤ τ ≤ 1,andσ∗ ≫ σ). This kernel function could greatly improve the memory ability of SVM. To memorize all the training samples,Wang et al. [33] pro- posed a generalization-memorization machine(GMM) under the principle of large margins, and this mechanism can obtain zero empirical risk easily. Hard Generalization-Mem -orization Machine (HGMM) [33] constructed a classification decision with f(x) =< w, φ(x) > +b + m � i=1 yiciδ(xi, x), and w ∈ Rd and b ∈ R by solving min w,b,c 1 2∥w∥2 + λ 2 ∥c∥2 s.t. yi(< w, φ(xi) > +b + m � j=1 yjcjδ(xi, xj)) ≥ 1, i = 1, ..., m, (1) where < ·, · > denotes the inner product, φ(·) is the mapping, and λ is the positive parameter, c = (c1, ..., cm)⊤ denotes the memory cost of the training sample, δ(xi, x) is a memory impact function that we define in advance. For a new sample x, if f(x) ¿ 0, it is classified as positive class with y = +1, otherwise it is classified as negative class with y = −1. In general, we can solve the pairwise problem of (1) min α 1 2α⊤Y(K(X, X) + 1 λ △ △⊤)Yα − 1⊤α, s.t. 1⊤Yα = 0, α ≥ 0, (2) where α ∈ Rm is a Lagrangian multiplier vector, K(·, ·) =< φ(·), φ(·) > is a kernel function, and 1 is a vector with the appropriate dimension. Specifically, a new sample x will be classified as +1 or -1 depending on the decision f(x) = m � i=1 yiαiK(xi, x) + b + m � i=1 yiciδ(xi, x). (3) Furthermore, by finding a non-zero component αk in the solution α(2) of the problem, we obtain b = yk − yk m � i=1 yi(αi K(xi, xk) + ciδ(xi, xk)). The above HGMM has good generalization ability for many problems, but it is time consuming for big data problems and cannot always classify all training samples quickly. For a memory problem, we not only need to be able to remember the training samples quickly, but also need to give labels quickly during testing. The optimization problem (1) with a memory cost function is a practical path to memorize the training samples. We consider the case where the constraints of this optimization problem are equivocal and propose a new construction on the optimization problem. From this perspective, for our machine learning model, we can solve the problem by solving a system of linear equations. In other words, we have a faster memory effect compared to HGMM, regardless of the complexity of the corresponding learning task. Also, we consider a new type of memory different from the weighted memory in HGMM and propose several constructions of new memory functions.3 III. MEMORY MODEL A. Weighted Impact Memory Model (WIMM) Our WIMM hires the decision function as f(x) =< w, φ(x) > +b + m � i=1 yiξiδ(xi, x), (4) where δ(xi, x) is the memory influence function, and it can be the similarity function between xi and x, e.g., δ(xi, xj) = 1 σ √ 2π exp (−∥ xi − xj ∥2 2σ2 ), σ > 0, (5) δ(xi, xj) = max{ρ− ∥ xi − xj ∥, 0}, ρ > 0, (6) δ(xi, xj) = � ∥ xi − xj ∥, if ∥ xi − xj ∥≤ ε, ε > 0, 0, else, (7) and δ(xi, xj) = � b ∥xi−xj∥, if xi ̸=, xj b > 0, 1, else. (8) The above functions measure the similarity between xi and xj. These influence functions are symmetric, and the memory of each training sample will have an effect on the prediction only if its memory cost is not zero. Then, when combined with the decision function (4), the effect of memory can be achieved. Therefore, our WIMM considers to min w,b,ξ 1 2∥w∥2 + γ 2 m � i=1 ξ2 i + λ m � i=1 m � j=1 yiyjξjδ(xi, xj), s.t. yi(< w, φ(xi) > +b + m � j=1 yjξjδ(xi, xj)) = 1, i = 1, ..., m, (9) where λ, γ is a positive parameter, ξ = (ξ1, ..., ξm)⊤ denotes the memory costs of training samples, and δ(xi, xj) is the memory impact function. Obviously, we use the decision function (4), set the memory cost as a variable and predefine the memory influence function in the decision. From the constraints of (9), it is necessary to remember all the training samples. The goal of problem (9) is to find the optimal strategy with the lowest possible memory cost as well as memory im- pact. To solve problem (9), we derive its Lagrangian function as L(w, b, ξ) = 1 2∥w∥2 + γ 2 m � i=1 ξ2 i + λ m � i=1 yi m � j=1 yjξjδ(xi, xj) + m � i=1 αi(1 − yi(< w, φ(xi) > +b + m � j=1 yjξjδ(xi, xj))), (10) where αi ∈ R is the Lagrangian multiplier with i = 1, . . . , m. Let its partial derivatives w.r.t. w, b, ξi and αi equal zeros, and we have                        ∂L ∂w = w − m � i=1 αiyiφ(xi), ∂L ∂b = m � i=1 αiyi, ∂L ∂ξi = cξi + λyi m � j=1 yjδ(xi, xj) − yiαi m � j=1 yjδ(xi, xj) = 0, ∂L ∂αi = 1 − yi(< w, φ(xi) >i +b + m � j=1 yjξjδ(xi, xj)). (11) Letting the partial derivative equal 0 gives                            w = m � i=1 αiyiφ(xi), m � i=1 αiyi = 0, ξi = αiyi m � j=1 yjδ(xi,xj)−λyi m � j=1 jδ(xi,xj) c , i = 1, . . . , m, yi(< w, φ(xi) >i +b + m � j=1 yjξjδ(xi, xj)) = 1, i = 1, . . . , m. (12) To facilitate the solution, we reformulate problem (12) as �YK(X, X)Y + Y △ △⊤Y Y1 1⊤Y 0 � �α b � = �1 + λ γ △ △⊤1 0 � , (13) where △ ∈ Rm×mand its elements are δ(xi, xj) with i, j = 1, ..., m.,, K(X, X) is a kernel matrix, α = (α1, ..., αm)⊤ and 1 = (1, ..., 1)⊤. After solving the above system of equations, the final decision is f(x) = m � i=1 yiαiK(xi, x) + b + m � i=1 yiξiδ(xi, x). (14) Furthermore, by in problem (12) we obtain ξ = (ξ1, ..., ξm)⊤. B. Maximum Impact Memory Model (MIMM) Different from the WIMM, our MIMM selects the closest training sample of the unknown sample to affect it by decision function as f(x) =< w, φ(x) > +b + yiξiδ(x, xk), (15) where xk is denoted as the centroid of the training point xi of the same kind. For example, suppose x+ and x− are positive and the negative class centroids, respectively. It is a straightforward way to use x+ or x− in δ(xk, x) as the memory influence function. Thus, our MIMM considers to min w,b,ξ 1 2∥w∥2 + γ 2 m � i=1 ξ2 i + λ m � i=1 ξiδi s.t. yi(< w, φ(xi) > +b) = 1 − ξiδi, i = 1, . . . , m, (16)4 where δi = δ(xk, xi) is the memory impact function we define. Instead of using all training samples in our MIMM decision, as in WIMM, we memorize the training samples by finding the closest training samples to the test sample points. Correspondingly, the Lagrangian function of (16) is L(w, b, ξ) = 1 2∥w∥2 + γ 2 m � i=1 ξ2 i + λ m � i=1 ξiδi + m � i=1 αi(1 − ξiδi − yi(< w, φ(xi) > +b)). (17) Find the partial derivatives of w.r.t. w, b, ξiand αi.,and we have                ∂L ∂w = w − m � i=1 αiyixi, ∂L ∂b = m � i=1 αiyi, ∂L ∂ξi = cξi + λδi − αiδi, ∂L ∂αi = 1 − ξiδi − yi(< w, φ(xi) > +b) i = 1, . . . , m. (18) Letting the partial derivative equal 0 gives                w = m � i=1 αiyixi, m � i=1 αiyi = 0, ξi = αiδi−λδi γ , i = 1, . . . , m, yi(< w, φ(xi) > +b) − 1 + ξiδi = 0, i = 1, . . . , m. (19) After simplifying the system of equations, we get: �YK(X, X)Y + YDD⊤Y Y1 1⊤Y 0 � �α b � = �1 + λ γ DD⊤1 0 � , (20) where D ∈ Rm×mand its a diagonal matrix with Dii = δi(i = 1, ..., m). Thus, the WIMM model obtains b and α by solving the system of linear equations (20), and then ξ by the optimality condition (19), the final decision is f(x) = m � i=1 yiαiK(xi, x) + b + yiξiδ(x, xk). (21) Indeed, the advantage of memorization becomes evident when we combine the memorization function with the LSSVM method. This combination allows us to carefully observe and analyze the impact of each memorization influence function on the overall performance of the model of the combined model. Specifically, consider a learner that incorporates a gen- eralized kernel Kg(x, x) = exp (− ∥xi−xj∥2 σ2 ) and a memory kernel Km, where the memory influence function is chosen as equations (5), (6), (7), and (8). Figure 1 illustrates the generated memory influence. With this memory influence, we can intuitively observe the range and degree of influence for each different influence function. We utilize the memory influence function to establish a rule, where classification is remembered only within a small region around the training data points. By adjusting the parameters of the influence function, we control the trade-off between generalization and memory in the algorithm. -2 -1 0 1 2 Generalization-memorization kernel1 0 1 2 3 4 5 -2 -1 0 1 2 Generalization-memorization kernel2 0 0.5 1 -2 -1 0 1 2 Generalization-memorization kernel3 0 0.5 1 1.5 -2 -1 0 1 2 Generalization-memorization kernel4 0 1 2 3 Fig. 1: Different types of memory kernels.1,2 ,3 and 4 with the influence function 5, 6, 7 and 8. Where red indicates the extent of memory influence and green indicates the extent of generalization influence. IV. DISCUSSION Proposition 1: The empirical risk of WIMM is zero if and only if problem (9) has at least one feasible solution. Similarly, the empirical risk of MIMM is zero if and only if problem (16) has at least one feasible solution. The feasibility of problems (9) or (16) depends on the proper- ties of the memory influence matrices △ or D. Generally, we have the following sufficient conditions for practical applica- tions. Proposition 2: The empirical risk of WIMM is zero if and only if matrix △ is nonsingular. Similarly, the empirical risk of MIMM is zero if and only if the D matrix is non-singular. Proof. We have considered the case where the △ matrix is non-singular. It can be shown that Y(K(X, X)+△)Y⊤ is also non-singular. Additionally, as r(1⊤Y) = 1, the problem (13) must have a unique solution. Similarly, it can be demonstrated that when the D matrix is non-singular, the problem (20) must also have a unique solution. This conclusion follows from proposition (1). □ Proposition 3: MIMM is equivalent to the LSSVM model if and only if D is a unit array and λ = 0. Proof. When D is a unitary matrix and λ = 0, the problem (20) is clearly in the form of a least squares system of linear equations to be solved. The proposition is proved and the conclusion holds. □ Proposition 4: WIMM is equivalent to the LSSVM model if and only if △ is a unit array and λ = 0. Proof. When △ is a unitary matrix and λ = 0, the problem (13) is clearly in the form of a system of linear equations solved by least squares. The proposition is proved and the conclusion holds. □ Fig. (2) gives information about the interrelationships be- tween the three memory kernels by comparing the memory5 Fig. 2: A memory relation diagram for MIMM,WIMM and SVMm [32], where yellow, pink and blue-gray denote the D, △ and km memory kernel matrices, respectively. kernels of equations (20), (13) and SVMm [32]. We can find that these three memory kernels are D, △ and km, which can be obtained by the matrix structure, D is a diagonal matrix, and △ and km are symmetric matrices. By tuning the parameters, D, △ and km can be varied to a unitary matrix. Thus there exists an intersection of these three memory kernels. Since △ can choose more than just one type of Gaussian kernel, △ contains km. Since △ and D have different influence functions, △ and D only have an intersection but no containment relationship. V. EXPERIMENTS This section utilizes several calibration datasets from UCI, for which Table (I) provides detailed information. We analyze the performance of our WIMM and MIMM models on various benchmark datasets, along with their execution times on large datasets. Additionally, we test the generalization performance of the two models and their ability to adapt to noise. The classical LSSVM utilizes linear kernels, while the SVMm and HGMM models employ linear generalization kernels and RBF memory kernels. In contrast, our WIMM and MIMM models both utilize linear kernels. All these models were implemented using MATLAB 2017a on a PC equipped with an Intel Core Duo processor (dual 4.2 GHz) and 32 GB of RAM. For the RBF kernel K(xi, xj) = exp(−σ ∥ xi − xj ∥2), we tested parameters σ from the set 2i|i = −6, −5, ..., 5, and for other models, we tested weighing parameters from the same set. To begin the comparison, we evaluated the memory performance of the linear kernel in WIMM and MIMM models on some small datasets, with the linear kernel in LSSVM used as the benchmark. To assess the memory capacity of the WIMM model, Table (II) presents the highest training and testing accuracies achieved by the WIMM model. This table provides valuable insights into the model’s ability to memorize and generalize effectively on the tested datasets. It can be observed from Table (II) that the WIMM model with the memory influence function (5, 6, 7) achieves a training accuracy of 100% on all datasets. However, the failure to reach 100% training accuracy can be attributed to the irreversibility of the △ term in the function and the impact of different influence functions on the data’s TABLE I: Details of benchmark datasets ID Name m n (a) Cleveland 173 13 (b) Ionosphere 351 34 (c) New-thyroid 215 4 (d) Parkinsons 195 22 (e) Sonar 208 60 (f) TicTacToe 958 27 (g) Vowel 988 13 (h) Wisconsin 683 9 (i) German 1000 20 (j) Shuttle 1829 9 (k) Segment 2308 19 (l) Waveform 5000 21 (m) TwoNorm 7400 20 (n) IJCNN01 49990 22 memory capacity. Among the various influence functions, the memory influence function (5) yields the highest test accuracy for most of the datasets. Consequently, for the remaining experiments, we utilize the memory influence function (5) as the basis for our WIMM model. Likewise, to evaluate the memory capacity of the MIMM model, Table (III) displays the maximum training and testing accuracies achieved by the MIMM model. It is evident from Table (III) that the MIMM model attains a training accuracy of 100% when using the memory influence function (8). The reason the other influence functions do not achieve 100% training accuracy is due to the irreversibility of D in these functions. The choice of different influence functions impacts the data’s memory capacity. Among the various influence functions, the memory influence function (8) yields the highest test accuracy for the majority of the datasets. As a result, for the subsequent experiments, we adopt the memory influence function (8) as the basis for our MIMM model. Next, to compare the running times of other memory models under optimal parameters, we recorded the execution times along with the corresponding accuracies on a larger dataset. This evaluation allows us to further assess the trade-off between the time consumed for memorization and the achieved performance on the same task for different memory models. For each dataset, approximately 70% of the total samples were randomly selected for training, ensuring that half of them belonged to the positive category and the other half to the negative category, while the remaining samples constituted the test set. This process was repeated five times, and the highest average training accuracy along with its standard deviation, the corresponding highest test accuracy, and the time taken to run the model once with optimal parameters were recorded for each dataset. The shortest time spent is indicated in bold in Table (IV). From Table (IV), it is evident that the test accuracies do not differ significantly. Notably, both WIMM and MIMM exhibit shorter execution times compared to HGMM and SVMm. This efficiency can be attributed to the fact that WIMM and MIMM models are solved as linear system of equations, whereas HGMM and SVMm are solved as quadratic programming problems. In practical applications, many tasks involve learning with labeled noise. Therefore, to examine the ability of WIMM and6 TABLE II: Testing and training accuracy of WIMM and LSSVM using memory effects. ID LSSVM WIMM1 WIMM2 WIMM3 WIMM4 LSSVM WIMM1 WIMM2 WIMM3 WIMM4 train(%) train(%) train(%) train(%) train(%) test(%) test(%) test(%) test(%) test(%) (a) 96.39±0.47 100 ± 0 100 ± 0 100 ± 0 90.77 ± 1.0 94.82±4.18 95.44±3.36 95.36±3.29 95.89 ± 4.49 95.89 ± 4.49 95.89 ± 4.49 92.85±6.16 (b) 89.46±0.47 100 ± 0 100 ± 0 100 ± 0 44.02 ± 1.6 88.3 ± 3.46 88.31±3.13 88.36±5.52 89.77 ± 3.86 89.77 ± 3.86 89.77 ± 3.86 42.24±9.23 (c) 94.08±0.86 100 ± 0 100 ± 0 100 ± 0 72.9 ± 2.08 93.66±3.41 97.79 ± 2.15 97.79 ± 2.15 97.79 ± 2.15 87.94±4.84 89.11 ± 7.7 88.31±4.52 (d) 91.42±1.15 100 ± 0 100 ± 0 100 ± 0 64.57±5.01 88.4 ± 7.44 94.73 ± 4.95 94.73 ± 4.95 94.73 ± 4.95 88.7 ± 5.84 91.8 ± 3.17 83.9 ± 4.3 (e) 87.99±1.36 100 ± 0 100 ± 0 100 ± 0 83.65 ± 1.4 79.48±2.85 86.79 ± 8.43 86.79 ± 8.43 86.79 ± 8.43 78.89±1.12 80.29±5.84 79.03±8.03 (f) 98.33±0.25 100 ± 0 100 ± 0 100 ± 0 100 ± 0 98.33 ± 1.0 98.33 ± 1.0 98.33 ± 1.0 98.33 ± 1.13 98.33 ± 1.13 98.33 ± 1.13 98.33 ± 1.62 98.33 ± 1.62 98.33 ± 1.62 98.33 ± 1.13 98.33 ± 1.13 98.33 ± 1.13 65.35±4.38 (g) 95.04±0.34 100 ± 0 100 ± 0 100 ± 0 75.05±7.08 95.04±2.08 100 ± 0 100 ± 0 100 ± 0 99.8 ± 0.28 99.8 ± 0.45 94.84±1.08 (h) 96.16±0.61 100 ± 0 100 ± 0 100 ± 0 95.65±0.71 96.18±2.45 96.63±1.52 96.65±2.25 96.78 ± 1.84 96.78 ± 1.84 96.78 ± 1.84 90.05±3.13 1,2 ,3 and 4 with the influence function 5, 6, 7 and 8. TABLE III: Testing and training accuracy of MIMM and LSSVM using memory effects. ID LSSVM MIMM1 MIMM2 MIMM3 MIMM4 LSSVM MIMM1 MIMM2 MIMM3 MIMM4 train(%) train(%) train(%) train(%) train(%) test(%) test(%) test(%) test(%) test(%) (a) 96.39±0.47 96.4 ± 0.79 94.83 ± 3.1 98.25 ± 0.9 100±0 94.82±4.18 95.28 ± 3.4 94.72±4.81 95.33±1.71 95.36 ± 2.6 95.36 ± 2.6 95.36 ± 2.6 (b) 89.46±0.47 100 ± 0 91.45±2.01 100 ± 0 100±0 88.3 ± 3.46 90.08±4.29 94.61 ± 3.64 94.61 ± 3.64 94.61 ± 3.64 88.61±1.67 89.75±4.63 (c) 94.08±0.86 100 ± 0 99.09±2.03 100 ± 0 100±0 93.66±3.41 98.64±1.18 98.57±1.28 98.72 ± 1.9 98.73 ± 1.9 98.73 ± 1.9 98.73 ± 1.9 (d) 91.42±1.15 100 ± 0 97.64±2.25 100 ± 0 100±0 88.4 ± 7.44 97.49 ± 1.49 97.49 ± 1.49 97.49 ± 1.49 97.07±1.93 96.42±3.03 96.3 ± 1.62 (e) 87.99±1.36 100 ± 0 86.85±2.73 100 ± 0 100±0 79.48±2.85 86.11±5.32 87.46±3.01 86.94 ± 2.2 88.47 ± 2.63 88.47 ± 2.63 88.47 ± 2.63 (f) 98.33±0.25 100 ± 0 98.33±1.44 100 ± 0 100±0 98.33 ± 1.0 98.33 ± 1.0 98.33 ± 1.0 98.33 ± 1.7 98.33 ± 1.7 98.33 ± 1.7 98.33 ± 0.93 98.33 ± 0.93 98.33 ± 0.93 98.33 ± 0.93 98.33 ± 0.93 98.33 ± 0.93 98.33 ± 1.13 98.33 ± 1.13 98.33 ± 1.13 (g) 95.04±0.34 100 ± 0 100 ± 0 100 ± 0 100±0 95.04±2.08 100 ± 0 100 ± 0 100 ± 0 100 ± 0 100 ± 0 100 ± 0 100 ± 0 100 ± 0 100 ± 0 100 ± 0 100 ± 0 100 ± 0 (h) 96.16±0.61 100 ± 0 97.23±1.29 100 ± 0 100±0 96.18±2.45 97.36±1.33 97.37 ± 0.82 97.37 ± 0.82 97.37 ± 0.82 97.08 ± 1.0 96.94±1.65 1,2 ,3 and 4 with the influence function 5, 6, 7 and 8. TABLE IV: Accuracy and time to train and test linear classifiers on benchmark datasets. ID SVMm HGMM WIMM MIMM SVMm HGMM WIMM MIMM train(%) train(%) train(%) train(%) test(%) test(%) test(%) test(%) time(s) time(s) time(s) time(s) (i) 100 ± 0 100 ± 0 100 ± 0 100 ± 0 76.1 ± 1.77 78.33±3.53 76.64±1.43 72.06±2.55 0.198s 0.196s 0.119s 0.105s (j) 100 ± 0 100 ± 0 100 ± 0 100 ± 0 99.95±0.12 100 ± 0 99.96±0.08 100 ± 0 0.738s 0.663s 0.344s 0.291s (h) 100 ± 0 100 ± 0 100 ± 0 100 ± 0 99.83±0.18 99.88±0.19 99.86±0.14 99.77±0.21 0.997s 1.256s 0.652s 0.393s (l) 100 ± 0 100 ± 0 100 ± 0 100 ± 0 90.16±0.81 88.27±0.61 86.42±0.85 83.24±0.67 5.835s 6.682s 2.362s 1.656s (m) 100 ± 0 100 ± 0 100 ± 0 100 ± 0 98.02±0.25 97.98±0.26 97.99 ± 0.5 95.09±0.56 15.793s 18.531s 5.888s 3.895s (n) ∗ ∗ 100 ± 0 100 ± 0 ∗ ∗ 93.80±0.26 97.37±0.08 787.645s 435.870s ’∗’ indicates a lack of sufficient operating memory. MIMM models to adapt to noise, we conducted experiments with datasets containing labeled noise. For certain datasets from Table (I), we randomly select 80% of the training samples to form the training set, while the remaining samples constitute the test set. We then introduce label noise to the training set, setting 5%, 10%, 15%, and gradually up to 50% of the labels to the opposite class. This process is repeated five times, and we record the highest test accuracy along with the corresponding average training accuracy for comparison with LSSVM. From Figures (3) and (4), we can observe the following trends: i) The training accuracy of LSSVM is not consistently 100% except for our WIMM and MIMM models. ii) The test performance of LSSVM is consistently lower than our model and exhibits instability with increasing label noise. iii) The test performance of our models (WIMM and MIMM) shows a gradual decline as the label noise increases in a regular manner. These observations suggest that our WIMM and MIMM models outperform LSSVM in handling labeled noise and offer more stable and robust performance under noisy conditions. Moreover, in many tasks, obtaining an adequate number of training samples can be particularly challenging. Hence, we further investigate the performance of these models in comparison to our WIMM and MIMM models under condi- tions of limited training samples. For selected datasets from Table (I), we randomly select 80% of the samples to form the training set, and the remaining samples constitute the test set. Subsequently, we vary the proportion of training samples used, ranging from 10% to 100%, in incremental steps. The models are tested on the dataset, and this process is repeated five times. We record the highest test accuracy along with the corresponding average training accuracy for comparison with LSSVM. From Figures (5) and (6), the following observations are made: i) Apart from our WIMM and MIMM models, the training accuracy of LSSVM is not consistently 100%. ii) The test performance of LSSVM is consistently inferior to our7 5% 15% 25% 35% 45% Percentage of noise used in Vowel 0.85 0.9 0.95 1 Training accuracy WIMM LSSVM 5% 15% 25% 35% 45% Percentage of noise used in Vowel 0.5 0.6 0.7 0.8 0.9 1 Test accuracy WIMM LSSVM 5% 15% 25% 35% 45% Percentage of noise used in Vowel 0.85 0.9 0.95 1 Training accuracy MIMM LSSVM 5% 15% 25% 35% 45% Percentage of noise used in Vowel 0.5 0.6 0.7 0.8 0.9 1 Test accuracy MIMM LSSVM Fig. 3: Training (left)/Testing (right) accuracy at different noise points 5% 15% 25% 35% 45% Percentage of noise used in Sonar 0.85 0.9 0.95 1 Training accuracy WIMM LSSVM 5% 15% 25% 35% 45% Percentage of noise used in Sonar 0.6 0.7 0.8 0.9 1 Test accuracy WIMM LSSVM 5% 15% 25% 35% 45% Percentage of noise used in Sonar 0.85 0.9 0.95 1 Training accuracy MIMM LSSVM 5% 15% 25% 35% 45% Percentage of noise used in Sonar 0.6 0.7 0.8 0.9 1 Test accuracy MIMM LSSVM Fig. 4: Training (left)/Testing (right) accuracy at different noise points8 10% 30% 50% 70% 90% Percentage of Vowel used 0.92 0.94 0.96 0.98 1 1.02 Training accuracy WIMM LSSVM 10% 30% 50% 70% 90% Percentage of Vowel used 0.4 0.5 0.6 0.7 0.8 0.9 1 Test accuracy WIMM LSSVM 10% 30% 50% 70% 90% Percentage of Vowel used 0.92 0.94 0.96 0.98 1 1.02 Training accuracy MIMM LSSVM 10% 30% 50% 70% 90% Percentage of Vowel used 0.5 0.6 0.7 0.8 0.9 1 Test accuracy MIMM LSSVM Fig. 5: Training(left)/Test(right) accuracy for different sample sizes. models, and its performance improves as more training data is used. iii) The test performance of our models (WIMM and MIMM) demonstrates a steady improvement as the number of training samples increases. These findings suggest that our WIMM and MIMM models outperform LSSVM, especially when training data is limited, and they consistently achieve higher test accuracy as the number of training samples grows. To compare the impact of different memory influence func- tions on the WIMM and MIMM models, we analyze the effect of memory kernel parameters on the models. Figures (7) and (8) illustrate this impact, with the LSSVM model used as a benchmark for comparison. In this experiment, we consider the models with parameters ranging from {0.1, 0.2, ..., 2}. Specifically, we focus on the Segment and Sonar datasets from Table (I). For these datasets, 80% of the training samples are randomly selected as the training set, and the remaining samples form the test set. The process is repeated five times, recording the highest test accuracy and its corresponding average training accuracy for comparison with LSSVM. As the WIMM model with the memory influence function (8) demonstrated poorer results in Table (II), we consider the influence case of this model. From Figures (7) and (8), we can make the following observations: i) The WIMM model is more sensitive to the parameters, and its ability to memorize is contingent on selecting the appropriate parameters. ii) The MIMM model, particularly with the memory influence function (8), exhibits greater stability, consistently memorizing the training samples while ensuring that the test performance remains superior to that of the LSSVM model. iii) Overall, our models consistently outperform the LSSVM model, provided that we select the right parameters. These findings emphasize the importance of parameter selection in the WIMM model, while the MIMM model offers a more robust performance with the chosen memory influence function. In general, our models demonstrate superior performance compared to the LSSVM model when the appropriate parameters are employed. VI. CONCLUSION We have presented two novel innovations in the traditional LSSVM framework: (i) We have proposed a replacement for the objective function of LSSVM, leading to improved perfor- mance. (ii) We have introduced a new memory generalization kernel that effectively incorporates the complete memory of the training data, achieving zero training error. As a result of these innovations, the MIMM and WIMM models have demonstrated superior generalization accuracy while maintain- ing the same computational complexity. Specifically, they still have involved solving a system of linear equations with a corresponding dimension, just like the current LSSVM im- plementation. Furthermore, our models have exhibited higher classification accuracy and have enhanced noise tolerance on certain datasets. Additionally, they have required less time and have cost to memorize training samples compared to existing memory models. In future work, we plan to extend our memory enhancement mechanism to other models and explore its applicability to a variety of other problems. In addition, we intend to consider multiple memory patterns in our memory model and introduce forgetting mechanisms to enrich the memory capacity to effectively solve a wider range of tasks.9 10% 30% 50% 70% 90% Percentage of Segment used 0.96 0.97 0.98 0.99 1 1.01 1.02 1.03 Training accuracy WIMM LSSVM 10% 30% 50% 70% 90% Percentage of Segment used 0.96 0.97 0.98 0.99 1 1.01 1.02 1.03 Test accuracy WIMM LSSVM 10% 30% 50% 70% 90% Percentage of Segment used 0.96 0.97 0.98 0.99 1 1.01 1.02 1.03 Training accuracy MIMM LSSVM 10% 30% 50% 70% 90% Percentage of Segment used 0.96 0.97 0.98 0.99 1 1.01 1.02 1.03 Test accuracy MIMM LSSVM Fig. 6: Training(left)/Test(right) accuracy for different sample sizes. 0.25 0.50 0.75 1.00 1.25 1.50 1.75 2 Memory functions are used in Segment 0.85 0.9 0.95 1 Training accuracy WIMM1 WIMM2 WIMM3 LSSVM 0.25 0.50 0.75 1.00 1.25 1.50 1.75 2 Memory functions are used in Segment 0.85 0.9 0.95 1 Test accuracy WIMM1 WIMM2 WIMM3 LSSVM 0.25 0.50 0.75 1.00 1.25 1.50 1.75 2 Memory functions are used in Sonar 0.7 0.75 0.8 0.85 0.9 0.95 1 Training accuracy WIMM1 WIMM2 WIMM3 LSSVM 0.25 0.50 0.75 1.00 1.25 1.50 1.75 2 Memory functions are used in Sonar 0.7 0.75 0.8 0.85 0.9 Test accuracy WIMM1 WIMM2 WIMM3 LSSVM Fig. 7: Training (left)/testing (right) accuracy with different influence functions.10 0.25 0.50 0.75 1.00 1.25 1.50 1.75 2 Memory functions are used in Segment 0.984 0.986 0.988 0.99 0.992 0.994 0.996 0.998 1 Training accuracy MIMM1 MIMM2 MIMM3 MIMM4 LSSVM 0.25 0.50 0.75 1.00 1.25 1.50 1.75 2 Memory functions are used in Segment 0.98 0.985 0.99 0.995 1 Test accuracy MIMM1 MIMM2 MIMM3 MIMM4 LSSVM 0.25 0.50 0.75 1.00 1.25 1.50 1.75 2 Memory functions are used in Sonar 0.86 0.88 0.9 0.92 0.94 0.96 0.98 1 Training accuracy MIMM1 MIMM2 MIMM3 MIMM4 LSSVM 0.25 0.50 0.75 1.00 1.25 1.50 1.75 2 Memory functions are used in Sonar 0.7 0.75 0.8 0.85 0.9 Test accuracy MIMM1 MIMM2 MIMM3 MIMM4 LSSVM Fig. 8: Training (left)/testing (right) accuracy with different influence functions. ACKNOWLEDGEMENT This work is supported in part by National Natural Science Foundation of China (Nos. 12271131, 62106112, 61866010,61966024 and 11871183), in part by the Natural Science Foundation of Hainan Province (No.120RC449), and in part by the Key Laboratory of Engineering Modeling and Statistical Computation of Hainan Province. REFERENCES [1] S. Chatterjee, “Learning and memorization,” pp. 755–763, 2018. [2] V. Feldman, “Does learning require memorization? a short tale about a long tail,” in Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing, 2020, pp. 954–959. [3] V. Vapnik and R. Izmailov, “Reinforced svm method and memorization mechanisms,” Pattern Recognition, vol. 119, p. 108018, 2021. [4] C. Cortes and V. Vapnik, “Support-vector networks,” Machine learning, vol. 20, pp. 273–297, 1995. [5] D. Arpit et al., “A closer look at memorization in deep networks,” in Proceedings of the 34th International Conference on Machine Learning, vol. 70, 2017, pp. 233–242. [6] G. Cohen et al., “Dnn or k-nn: That is the generalize vs. memorize question,” arXiv preprint arXiv:1805.06822, 2018. [7] J. L. Elman, “Finding structure in time,” Cognitive science, vol. 14, no. 2, pp. 179–211, 1990. [8] Z. Yang et al., “Rethinking bias-variance trade-off for generalization of neural networks,” in International Conference on Machine Learning. PMLR, 2020, pp. 10 767–10 777. [9] G. Hinton, O. Vinyals, and J. Dean, “Distilling the knowledge in a neural network,” arXiv preprint arXiv:1503.02531, 2015. [10] I. Goodfellow, Y. Bengio, and A. Courville, Deep learning. MIT press, 2016. [11] C. M. Bishop, Neural networks for pattern recognition. Oxford university press, 1995. [12] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural computation, vol. 9, no. 8, pp. 1735–1780, 1997. [13] C. Zhang et al., “Understanding deep learning (still) requires rethinking generalization,” Communications of the ACM, vol. 64, no. 3, pp. 107– 115, 2021. [14] Z. Yang et al., “Resmem: Learn what you can and memorize the rest,” arXiv preprint arXiv:2302.01576, 2023. [15] S. Wan and Z. Niu, “A hybrid e-learning recommendation approach based on learners’ influence propagation,” IEEE Transactions on Knowl- edge and Data Engineering, vol. 32, no. 5, pp. 827–840, 2019. [16] A. Cully and Y. Demiris, “Online knowledge level tracking with data- driven student models and collaborative filtering,” IEEE Transactions on Knowledge and Data Engineering, vol. 32, no. 10, pp. 2000–2013, 2019. [17] N. S. Clayton et al., “Elements of episodic–like memory in animals,” Philosophical Transactions of the Royal Society of London. Series B: Biological Sciences, vol. 356, no. 1413, pp. 1483–1491, 2001. [18] A. N. Rafferty et al., “Faster teaching via pomdp planning,” Cognitive science, vol. 40, no. 6, pp. 1290–1332, 2016. [19] Q. Kang and W. P. Tay, “Sequential multi-class labeling in crowdsourc- ing,” IEEE Transactions on Knowledge and Data Engineering, vol. 31, no. 11, pp. 2190–2199, 2018. [20] I. P. Androulakis, “Dynamic programming: Stochastic shortest path problems.” 2009. [21] B. Settles and B. Meeder, “A trainable spaced repetition model for language learning,” in Proceedings of the 54th annual meeting of the association for computational linguistics (volume 1: long papers), 2016, pp. 1848–1858. [22] J. Ke et al., “Learning to delay in ride-sourcing systems: a multi- agent deep reinforcement learning framework,” IEEE Transactions on Knowledge and Data Engineering, vol. 34, no. 5, pp. 2280–2292, 2020. [23] Y. Zhang et al., “Cost-sensitive portfolio selection via deep reinforce- ment learning,” IEEE Transactions on Knowledge and Data Engineer- ing, vol. 34, no. 1, pp. 236–248, 2020. [24] U. Upadhyay, A. De, and M. Gomez Rodriguez, “Deep reinforcement learning of marked temporal point processes,” Advances in Neural Information Processing Systems, vol. 31, 2018. [25] J. R. Anderson, “Act: A simple theory of complex cognition.” American psychologist, vol. 51, no. 4, p. 355, 1996. [26] H. Pashler et al., “Predicting the optimal spacing of study: A multiscale context model of memory,” Advances in neural information processing systems, vol. 22, 2009. [27] J. Su et al., “Optimizing spaced repetition schedule by capturing the dynamics of memory,” IEEE Transactions on Knowledge and Data Engineering, 2023. [28] J. Ye, J. Su, and Y. Cao, “A stochastic shortest path algorithm for optimizing spaced repetition scheduling,” in Proceedings of the 28th11 ACM SIGKDD Conference on Knowledge Discovery and Data Mining, 2022, pp. 4381–4390. [29] G. B. Maddox et al., “The role of forgetting rate in producing a benefit of expanded over equal spaced retrieval in young and older adults.” Psychology and aging, vol. 26, no. 3, p. 661, 2011. [30] S. Reddy et al., “Unbounded human learning: Optimal scheduling for spaced repetition,” in Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, 2016, pp. 1815–1824. [31] A. Nioche et al., “Improving artificial teachers by considering how people learn and forget,” in 26th International Conference on Intelligent User Interfaces, 2021, pp. 445–453. [32] V. Vapnik and R. Izmailov, “Reinforced svm method and memorization mechanisms,” Pattern Recognition, vol. 119, p. 108018, 2021. [33] Z. Wang and Y.-H. Shao, “Generalization-memorization machines,” arXiv preprint arXiv:2207.03976, 2022. [34] A. J. Smola and B. Sch¨olkopf, Learning with kernels. Citeseer, 1998, vol. 4. [35] V. N. Vapnik, “An overview of statistical learning theory,” IEEE trans- actions on neural networks, vol. 10, no. 5, pp. 988–999, 1999. [36] V. Vapnik, Estimation of dependences based on empirical data. Springer Science & Business Media, 2006. [37] B. Sch¨olkopf et al., “New support vector algorithms,” Neural computa- tion, vol. 12, no. 5, pp. 1207–1245, 2000. [38] Jayadeva, R. Khemchandani, and S. Chandra, “Twin support vector machines for pattern classification,” IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 29, pp. 905–910, 2007. [39] J. A. Suykens and J. Vandewalle, “Least squares support vector machine classifiers,” Neural processing letters, vol. 9, pp. 293–300, 1999. [40] C. Zhang et al., “Understanding deep learning (still) requires rethinking generalization,” Communications of the ACM, vol. 64, no. 3, pp. 107– 115, 2021. [41] M. Belkin et al., “Reconciling modern machine-learning practice and the classical bias–variance trade-off,” Proceedings of the National Academy of Sciences, vol. 116, no. 32, pp. 15 849–15 854, 2019.